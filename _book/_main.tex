% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\usepackage[normalem]{ulem}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsmath}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={BIOSTATS},
  pdfauthor={Akira Terui},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{BIOSTATS}
\author{Akira Terui}
\date{Last updated on 2023-06-14}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{introduction}{%
\chapter*{Introduction}\label{introduction}}
\addcontentsline{toc}{chapter}{Introduction}

This textbook aims to introduce fundamental statistical techniques and their applications to biological data. A unique aspect of this book is the ``flipped-order'' introduction. Many statistics courses start with theory; yet, I found it difficult for those unfamiliar with statistics. I will start with a real example of the method, followed by the explanation for an underlying theory/concept. The author is an ecologist, so some methods in this book might not be popular in other fields.

\hypertarget{descriptive-statistics}{%
\chapter{Descriptive Statistics}\label{descriptive-statistics}}

Descriptive statistics are a set of summary measures that provide a concise overview of a dataset. They help us understand the characteristics and properties of the data without delving into complex statistical analyses. Some commonly used descriptive statistics include the mean, standard deviation, and median.

To illustrate the concept, let's consider fish length measurement \(x\). Each fish is identified by a subscript, and their lengths are denoted as follows:

\[
x_1 = 15.9\\
x_2 = 15.1\\
x_3 = 21.9\\
x_4 = 13.3\\
x_5 = 24.4\\
\]Often times, we use subscript \(i\) (or any character you like) instead of actual number to indicate a given data point. For example, we write fish length \(x_i\) for individual \(i\). Alternatively, instead of writing each individual data point, we can represent them as a vector using boldface, denoted as \(\pmb{x}\). In this case, the vector \(\pmb{x}\) can be expressed as:

\[
\pmb{x} = \{15.9, 15.1, 21.9, 13.3, 24.4\}
\]

Now let's see how we represent summary statistics of vector \(\pmb{x}\).

\hypertarget{central-tendency}{%
\section{Central Tendency}\label{central-tendency}}

\hypertarget{measures-of-central-tendency}{%
\subsection{Measures of Central Tendency}\label{measures-of-central-tendency}}

Central tendency measures (Table \ref{tab:central}) provide insights into the typical or central value of a dataset. There are three commonly used measures:

\begin{itemize}
\item
  \textbf{Arithmetic Mean}. This is the most commonly used measure of central tendency. It represents the \emph{additive} average of the data. To calculate the arithmetic mean, you sum up all the values and divide the total by the number of data points. It can be heavily influenced by extreme values, known as outliers.
\item
  \textbf{Geometric Mean}. The geometric mean is a \emph{multiplicative} average. It is always smaller than the arithmetic mean and less sensitive to unusually large values. However, it is not applicable when the data contain negative values.
\item
  \textbf{Median}. The median is the value that separates the higher half from the lower half of the dataset. It represents the 50th percentile data point. The median is less affected by outliers compared to the arithmetic mean. To calculate the median, you arrange the data in ascending order and select the middle value if the dataset has an odd number of values. If the dataset has an even number of values, you take the average of the two middle values.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.2278}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.7722}}@{}}
\caption{\label{tab:central} Common measures of central tendency. \(N\) refers to the number of data points.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Measure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Equation
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Measure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Equation
\end{minipage} \\
\midrule()
\endhead
Arithmetic mean \(\mu\) & \(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \frac{\sum_i^N x_i}{N}                                                                                                                                                             
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \) \\
Geometric mean \(\mu_{ge}\) & \(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     (\prod_i^N x_i)^{\frac{1}{N}}                                                                                                                                                      
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \) \\
Median \(\mu_{med}\) & \(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \begin{aligned}                                                                                                                                                                    
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     &x_{(\frac{N + 1}{2}^\text{th})} &&\text{if N is odd number}\\                                                                                                                     
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     &\frac{1}{2}[x_{(\frac{N}{2}^\text{th})} + x_{(\frac{N}{2} + 1^\text{th})}] &&\text{if N is even number}                                                                           
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \end{aligned}\) \\
\bottomrule()
\end{longtable}

\hypertarget{r-exercise}{%
\subsection{R Exercise}\label{r-exercise}}

To learn more about these measures, let's create vectors \(\pmb{x} = \{15.9, 15.1, 21.9, 13.3, 24.4\}\) and \(\pmb{y} = \{15.9, 15.1, 21.9, 53.3, 24.4\}\) -- \(\pmb{y}\) is identical to \(\pmb{x}\) but contains one outlier value. How does this make difference? To construct vectors in R, we use \texttt{c()}, a function that stands for ``construct.'' Below is the script:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# construct vectors x and y}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{15.9}\NormalTok{, }\FloatTok{15.1}\NormalTok{, }\FloatTok{21.9}\NormalTok{, }\FloatTok{13.3}\NormalTok{, }\FloatTok{24.4}\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{15.9}\NormalTok{, }\FloatTok{15.1}\NormalTok{, }\FloatTok{21.9}\NormalTok{, }\FloatTok{53.3}\NormalTok{, }\FloatTok{24.4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Confirm you constructed them correctly:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.9 15.1 21.9 13.3 24.4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.9 15.1 21.9 53.3 24.4
\end{verbatim}

Cool! Now we can calculate summary statistics of \texttt{x} and \texttt{y}.

\textbf{Arithmetic mean}

While R has a function for arithmetic \texttt{mean()}, let's try to calculate the value from scratch:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for vector x}
\NormalTok{n\_x }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(x) }\CommentTok{\# the number of elements in x = the number of data points}
\NormalTok{sum\_x }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(x) }\CommentTok{\# summation for x}
\NormalTok{mu\_x }\OtherTok{\textless{}{-}}\NormalTok{ sum\_x }\SpecialCharTok{/}\NormalTok{ n\_x }\CommentTok{\# arithmetic mean}
\FunctionTok{print}\NormalTok{(mu\_x) }\CommentTok{\# print calculated value}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 18.12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for vector y; we can calculate directly too}
\NormalTok{mu\_y }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(y) }\SpecialCharTok{/} \FunctionTok{length}\NormalTok{(y)}
\FunctionTok{print}\NormalTok{(mu\_y) }\CommentTok{\# print calculated value}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 26.12
\end{verbatim}

Compare with outputs from \texttt{mean()} :

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{mean}\NormalTok{(x))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 18.12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{mean}\NormalTok{(y))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 26.12
\end{verbatim}

\textbf{Geometric Mean}

Unfortunately, there is no build-in function for geometric mean \(\mu_{ge}\) in R (as far as I know; there are packages though). But, we can calculate the value from scratch again:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for vector x}
\NormalTok{prod\_x }\OtherTok{\textless{}{-}} \FunctionTok{prod}\NormalTok{(x) }\CommentTok{\# product of vector x; x1 * x2 * x3...}
\NormalTok{n\_x }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(x)}
\NormalTok{mug\_x }\OtherTok{\textless{}{-}}\NormalTok{ prod\_x}\SpecialCharTok{\^{}}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ n\_x) }\CommentTok{\# \^{} means power}
\FunctionTok{print}\NormalTok{(mug\_x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 17.63648
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for vector y}
\NormalTok{mug\_y }\OtherTok{\textless{}{-}} \FunctionTok{prod}\NormalTok{(y)}\SpecialCharTok{\^{}}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/} \FunctionTok{length}\NormalTok{(y))}
\FunctionTok{print}\NormalTok{(mug\_y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 23.28022
\end{verbatim}

\textbf{Median}

Lastly, let's do the same for median:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for vector x}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(x) }\CommentTok{\# sort x from small to large}
\NormalTok{index }\OtherTok{\textless{}{-}}\NormalTok{ (}\FunctionTok{length}\NormalTok{(x) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/} \DecValTok{2} \CommentTok{\# (N + 1)/2 th index as length(x) is an odd number}
\NormalTok{med\_x }\OtherTok{\textless{}{-}}\NormalTok{ x[index]}
\FunctionTok{print}\NormalTok{(med\_x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for vector y}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(y) }\CommentTok{\# sort y from small to large}
\NormalTok{med\_y }\OtherTok{\textless{}{-}}\NormalTok{ y[(}\FunctionTok{length}\NormalTok{(y) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/} \DecValTok{2}\NormalTok{]}
\FunctionTok{print}\NormalTok{(med\_y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 21.9
\end{verbatim}

Compare with outputs from \texttt{median()}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{median}\NormalTok{(x))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{median}\NormalTok{(y))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 21.9
\end{verbatim}

\hypertarget{variation}{%
\section{Variation}\label{variation}}

\hypertarget{measures-of-variation}{%
\subsection{Measures of Variation}\label{measures-of-variation}}

Variation measures (Table \ref{tab:variation}) provide information about the spread of data points.

\begin{itemize}
\item
  \textbf{Variance.} Variance is a statistical measure that quantifies the spread or dispersion of a dataset. It provides a numerical value that indicates how far individual data points in a dataset deviate from the mean or average value. In other words, variance measures the average squared difference between each data point and the mean. \textbf{Standard deviation (SD) is the square root of variance}.
\item
  \textbf{Inter-Quantile Range.} The interquartile range (IQR) is a statistical measure that provides information about the spread or dispersion of a dataset, specifically focusing on the middle 50\% of the data. It is a robust measure of variability that is less affected by outliers compared to variance.
\item
  \textbf{Median Absolute Deviation.} Median Absolute Deviation (MAD) is similar to variance, but provides a robust estimation of variability that is less affected by outliers compared to variance. MAD is defined as the median of the absolute deviations from the data's median.
\item
  \textbf{Coefficient of Variation.} The coefficient of variation (CV) is a statistical measure that expresses the relative variability of a dataset in relation to its mean. It is particularly useful when comparing the variability of different datasets that have different scales or units of measurement.
\item
  \textbf{MAD/Median.} MAD/Median is a statistical measure used to assess the relative variability of a dataset without assuming any specific distribution or parametric model. CV is sensitive to outliers because of its reliance on the arithmetic mean. However, MAD/Median is robust to this issue.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.3103}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.6897}}@{}}
\caption{\label{tab:variation} Common measures of variation. \(N\) refers to the number of data points.}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Measure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Equation
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Measure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Equation
\end{minipage} \\
\midrule()
\endhead
Variance \(\sigma^2\) (standard deviation \(\sigma\)) & \(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \frac{\sum_i^N (x_i - \mu)^2}{N}                                                             
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \) \\
Inter-Quantile Range IQR (\(x_l\) and \(x_h\) are \(l^{th}\) and \(h^{th}\) percentiles, respectively) & \(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |x_{l} - x_{h}|                                                                              
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \) \\
Median Absolute Deviation (MAD) & \(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \text{Median}(|x_i-\mu_{med}|)                                                               
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \) \\
Coefficient of Variation (CV) & \(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \frac{\sigma}{\mu}                                                                           
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \) \\
MAD/Median & \(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \frac{\text{MAD}}{\mu_{med}}                                                                 
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \) \\
\bottomrule()
\end{longtable}

\hypertarget{r-exercise-1}{%
\subsection{R Exercise}\label{r-exercise-1}}

\textbf{Variance, SD, and CV}

Let's try variance, SD, and CV:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for x}
\NormalTok{sqd\_x }\OtherTok{\textless{}{-}}\NormalTok{ (x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x))}\SpecialCharTok{\^{}}\DecValTok{2} \CommentTok{\# sqared deviance}
\NormalTok{sum\_sqd\_x }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(sqd\_x)}

\NormalTok{var\_x }\OtherTok{\textless{}{-}}\NormalTok{ sum\_sqd\_x }\SpecialCharTok{/} \FunctionTok{length}\NormalTok{(x)}
\NormalTok{sd\_x }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(var\_x) }\CommentTok{\# sqrt(): square root}
\NormalTok{cv\_x }\OtherTok{\textless{}{-}}\NormalTok{ sd\_x }\SpecialCharTok{/} \FunctionTok{mean}\NormalTok{(x)}

\FunctionTok{print}\NormalTok{(var\_x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 18.2016
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(sd\_x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.266333
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(cv\_x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2354489
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for y}
\NormalTok{var\_y }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((y }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(y))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{length}\NormalTok{(y)}
\NormalTok{sd\_y }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(var\_y)}
\NormalTok{cv\_y }\OtherTok{\textless{}{-}}\NormalTok{ sd\_y }\SpecialCharTok{/} \FunctionTok{mean}\NormalTok{(y)}

\FunctionTok{print}\NormalTok{(var\_y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 197.0816
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(sd\_y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 14.03858
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(cv\_y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.5374646
\end{verbatim}

\textbf{IQR, MAD, and MAD/Median}

Let's try IQR, MAD, and MAD/Median. IQR can be defined for given percentiles. Here, let me use 25 and 75 percentiles as \(x_l\) and \(x_h\).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for x}
\DocumentationTok{\#\# IQR}
\NormalTok{x\_l }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(x, }\FloatTok{0.25}\NormalTok{) }\CommentTok{\# quantile(): return quantile values, 25 percentile}
\NormalTok{x\_h }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(x, }\FloatTok{0.75}\NormalTok{) }\CommentTok{\# quantile(): return quantile values, 75 percentile}
\NormalTok{iqr\_x }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(x\_l }\SpecialCharTok{{-}}\NormalTok{ x\_h) }\CommentTok{\# abs(): absolute value}

\DocumentationTok{\#\# MAD}
\NormalTok{ad\_x }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x))}
\NormalTok{mad\_x }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(ad\_x)}

\DocumentationTok{\#\# MAD/median}
\NormalTok{mad\_m\_x }\OtherTok{\textless{}{-}}\NormalTok{ mad\_x }\SpecialCharTok{/} \FunctionTok{median}\NormalTok{(x)}

\FunctionTok{print}\NormalTok{(iqr\_x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 25% 
## 6.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(mad\_x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.78
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(mad\_m\_x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2377358
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for y}
\DocumentationTok{\#\# IQR}
\NormalTok{y\_q }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(y, }\FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.75}\NormalTok{)) }\CommentTok{\# return as a vector}
\NormalTok{iqr\_y }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(y\_q[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ y\_q[}\DecValTok{2}\NormalTok{]) }\CommentTok{\# y\_q[1] = 25 percentile; y\_q[2] = 75 percentile}

\DocumentationTok{\#\# MAD}
\NormalTok{mad\_y }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(}\FunctionTok{abs}\NormalTok{(y }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(y)))}

\DocumentationTok{\#\# MAD/median}
\NormalTok{mad\_m\_y }\OtherTok{\textless{}{-}}\NormalTok{ mad\_y }\SpecialCharTok{/} \FunctionTok{median}\NormalTok{(y)}

\FunctionTok{print}\NormalTok{(iqr\_y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 25% 
## 8.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(mad\_y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10.22
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(mad\_m\_y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4666667
\end{verbatim}

\hypertarget{laboratory}{%
\section{Laboratory}\label{laboratory}}

\hypertarget{comparing-central-tendency-measures}{%
\subsection{Comparing Central Tendency Measures}\label{comparing-central-tendency-measures}}

What are the differences of the three measures of central tendency? To investigate this further, let's perform the following exercise.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a new vector \texttt{z} with length \(1000\) as \texttt{exp(rnorm(n\ =\ 1000,\ mean\ =\ 0,\ sd\ =\ 0.1))}, and calculate the arithmetic mean, geometric mean, and median.
\item
  Draw a histogram of \texttt{z} using functions \texttt{tibble()}, \texttt{ggplot()}, and \texttt{geom\_histogram()}.
\item
  Draw vertical lines of arithmetic mean, geometric mean, and median on the histogram with different colors using a function \texttt{geom\_vline()} .
\item
  Compare the values of the central tendency measures.
\item
  Create a new vector \texttt{z\_rev} as \texttt{-z\ +\ max(z)\ +\ 0.1}, and repeat step 1 -- 4.
\end{enumerate}

\hypertarget{comparing-variation-measures}{%
\subsection{Comparing Variation Measures}\label{comparing-variation-measures}}

Why do we have absolute (variance, SD, MAD, IQR) and relative measures (CV, MAD/Median) of variation? To understand this, suppose we have 100 measurements of fish weight in unit ``gram.'' (\texttt{w} in the following script)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{, }\AttributeTok{mean =} \DecValTok{10}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)}
\FunctionTok{head}\NormalTok{(w) }\CommentTok{\# show first 10 elements in w}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  9.237455  9.171337 10.834474  9.032348  9.971185 10.232525
\end{verbatim}

Using this data, perform the following exercise:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Convert the unit of \texttt{w} to ``milligram'' and create a new vector \texttt{m}.
\item
  Calculate SD and MAD for \texttt{w} and \texttt{m}.
\item
  Calculate CV and MAD/Median for \texttt{w} and \texttt{m}.
\end{enumerate}

\hypertarget{sampling}{%
\chapter{Sampling}\label{sampling}}

\emph{``Why do I need statistics in the first place?''} This was the initial question that arose when I entered the field of ecology. Initially, I assumed it would be a straightforward query with an immediate response. However, I soon realized that it is a profound question with a complex answer. In short, ``we need statistics because we often possess only partial information about what we seek to understand.'' Now, let's explore the more elaborate explanation below.

\hypertarget{the-unknown-garden-plant-example}{%
\section{The Unknown: Garden Plant Example}\label{the-unknown-garden-plant-example}}

Consider a scenario where we are conducting a study on plant height in a garden. In this garden, there exists a thousand of individual plants, making it impractical for a single researcher to measure all of them. Instead, due to resource limitations, a sample of \(10\) plants was selected to \textbf{\emph{calculate}} the average height and the extent of variation among these plant individuals:

\begin{verbatim}
## # A tibble: 10 x 4
##     ...1 plant_id height unit 
##    <dbl>    <dbl>  <dbl> <chr>
##  1     1        1   16.9 cm   
##  2     2        2   20.9 cm   
##  3     3        3   15.8 cm   
##  4     4        4   28   cm   
##  5     5        5   21.6 cm   
##  6     6        6   15.9 cm   
##  7     7        7   22.4 cm   
##  8     8        8   23.7 cm   
##  9     9        9   22.9 cm   
## 10    10       10   18.5 cm
\end{verbatim}

Cool. Let's use this data set to learn about the pitfall behind this. Create a vector of plant height \texttt{h} and put it in a \texttt{tibble()} to analyze it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{16.9}\NormalTok{, }\FloatTok{20.9}\NormalTok{, }\FloatTok{15.8}\NormalTok{, }\DecValTok{28}\NormalTok{, }\FloatTok{21.6}\NormalTok{, }\FloatTok{15.9}\NormalTok{, }\FloatTok{22.4}\NormalTok{, }\FloatTok{23.7}\NormalTok{, }\FloatTok{22.9}\NormalTok{, }\FloatTok{18.5}\NormalTok{)}

\NormalTok{df\_h1 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{plant\_id =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, }\CommentTok{\# a vector from 1 to 10 by 1}
                \AttributeTok{height =}\NormalTok{ h, }\CommentTok{\# height}
                \AttributeTok{unit =} \StringTok{"cm"}\NormalTok{) }\CommentTok{\# unit}
\end{Highlighting}
\end{Shaded}

This format (\texttt{tibble()}) is better than a raw vector of height because it allows more flexible analysis. Let's add columns of \texttt{mu\_height} and \texttt{var\_height} using \texttt{mutate()}, a function that adds new column(s) to an existing \texttt{tibble()} (or \texttt{data.frame()}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# nrow() returns the number of rows}
\CommentTok{\# while piping, "." refers to the dataframe inherited }
\CommentTok{\# i.e., nrow(.) counts the number of rows in df\_h1}
\NormalTok{df\_h1 }\OtherTok{\textless{}{-}}\NormalTok{ df\_h1 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{mu\_height =} \FunctionTok{mean}\NormalTok{(height),}
         \AttributeTok{var\_height =} \FunctionTok{sum}\NormalTok{((height }\SpecialCharTok{{-}}\NormalTok{ mu\_height)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{nrow}\NormalTok{(.))}
\end{Highlighting}
\end{Shaded}

Awesome, we were able to get the average height and the variance! -- \textbf{however, how confident are you?} We obtained plant height only from 10\ldots out of 1000. Are they different if we measure another set of 10 plant individuals? Let's see:

\begin{verbatim}
## # A tibble: 10 x 4
##     ...1 plant_id height unit 
##    <dbl>    <dbl>  <dbl> <chr>
##  1    11       11   27.6 cm   
##  2    12       12   21.9 cm   
##  3    13       13   16.9 cm   
##  4    14       14    8.9 cm   
##  5    15       15   25.6 cm   
##  6    16       16   19.8 cm   
##  7    17       17   19.9 cm   
##  8    18       18   24.7 cm   
##  9    19       19   24.1 cm   
## 10    20       20   23   cm
\end{verbatim}

Create another \texttt{tibble()} :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{27.6}\NormalTok{, }\FloatTok{21.9}\NormalTok{, }\FloatTok{16.9}\NormalTok{, }\FloatTok{8.9}\NormalTok{, }\FloatTok{25.6}\NormalTok{, }\FloatTok{19.8}\NormalTok{, }\FloatTok{19.9}\NormalTok{, }\FloatTok{24.7}\NormalTok{, }\FloatTok{24.1}\NormalTok{, }\DecValTok{23}\NormalTok{)}

\NormalTok{df\_h2 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{plant\_id =} \DecValTok{11}\SpecialCharTok{:}\DecValTok{20}\NormalTok{, }\CommentTok{\# a vector from 11 to 20 by 1}
                \AttributeTok{height =}\NormalTok{ h,}
                \AttributeTok{unit =} \StringTok{"cm"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{mu\_height =} \FunctionTok{mean}\NormalTok{(height),}
         \AttributeTok{var\_height =} \FunctionTok{sum}\NormalTok{((height }\SpecialCharTok{{-}}\NormalTok{ mu\_height)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{nrow}\NormalTok{(.))}

\FunctionTok{print}\NormalTok{(df\_h2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 5
##    plant_id height unit  mu_height var_height
##       <int>  <dbl> <chr>     <dbl>      <dbl>
##  1       11   27.6 cm         21.2       25.8
##  2       12   21.9 cm         21.2       25.8
##  3       13   16.9 cm         21.2       25.8
##  4       14    8.9 cm         21.2       25.8
##  5       15   25.6 cm         21.2       25.8
##  6       16   19.8 cm         21.2       25.8
##  7       17   19.9 cm         21.2       25.8
##  8       18   24.7 cm         21.2       25.8
##  9       19   24.1 cm         21.2       25.8
## 10       20   23   cm         21.2       25.8
\end{verbatim}

Wow, that's totally different.

\hypertarget{linking-part-to-the-whole}{%
\section{Linking Part to the Whole}\label{linking-part-to-the-whole}}

The exercise highlights an important takeaway: what we can determine from the above data is the average and variance of the sample, \textbf{which may not perfectly represent the characteristics of the entire garden.}

In the field of biological research, it is often impractical or impossible to sample the entire population, so we must rely on estimating the unknowns (in this case, the \emph{mean} and \emph{variance}) from the available samples. This is where statistics comes into play, offering a tool to infer information about the entire population based on partial information obtained from the samples.

The unknowns we are interested in, which the population mean and variance in this example, are referred to as ``\textbf{parameters.}'' These parameters \uline{\emph{cannot be directly measured}} but can be \uline{\emph{estimated}} from samples through statistical inference.

Provided that certain assumptions are met, the \emph{sample mean} is the unbiased point estimate of the \emph{population} \emph{mean}. The \textbf{``\emph{unbiased}''} means that the sample means -- if we repeat the sampling process -- are centered around the population mean. In the meantime, the sample variance -- if we use the formula in Chapter \ref{descriptive-statistics} -- is ``\textbf{\emph{biased}}.'' It tends to be smaller than the population variance.

Let's explore this concept further through simple simulations. Suppose we have data on a thousand plant individuals, although this scenario may be unrealistic in practice. However, by conducting these simulations, we can examine how different sample means and variances can deviate from the true values.

Download the data \href{https://github.com/aterui/biostats/blob/master/data_raw/data_plant_height.csv}{here} containing height measurements of thousand individuals, and place this file under \texttt{data\_raw/} in your project directory. You can load this \texttt{csv} file in R as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load csv data on R}
\NormalTok{df\_h0 }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data\_raw/data\_plant\_height.csv"}\NormalTok{)}

\CommentTok{\# show the first 10 rows}
\FunctionTok{print}\NormalTok{(df\_h0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1,000 x 4
##     ...1 plant_id height unit 
##    <dbl>    <dbl>  <dbl> <chr>
##  1     1        1   16.9 cm   
##  2     2        2   20.9 cm   
##  3     3        3   15.8 cm   
##  4     4        4   28   cm   
##  5     5        5   21.6 cm   
##  6     6        6   15.9 cm   
##  7     7        7   22.4 cm   
##  8     8        8   23.7 cm   
##  9     9        9   22.9 cm   
## 10    10       10   18.5 cm   
## # i 990 more rows
\end{verbatim}

Using this synthetic dataset (I generated through a random value generator), we can calculate the true mean and variance (reference values). It is important to note that in this case, we use the term ``calculate'' for the mean and variance because they represent the parameters of the entire population, which are known to us in this scenario.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(df\_h0}\SpecialCharTok{$}\NormalTok{height)}
\NormalTok{sigma2 }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((df\_h0}\SpecialCharTok{$}\NormalTok{height }\SpecialCharTok{{-}}\NormalTok{ mu)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{nrow}\NormalTok{(df\_h0)}

\FunctionTok{print}\NormalTok{(mu)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 19.9426
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(sigma2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 26.74083
\end{verbatim}

We can simulate the sampling of 10 plant individuals by randomly selecting 10 rows from \texttt{df\_h0}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_i }\OtherTok{\textless{}{-}}\NormalTok{ df\_h0 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{sample\_n}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{) }\CommentTok{\# size specifies the number of rows to be selected randomly}

\FunctionTok{print}\NormalTok{(df\_i)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 4
##     ...1 plant_id height unit 
##    <dbl>    <dbl>  <dbl> <chr>
##  1   308      308   22.8 cm   
##  2   461      461   17.7 cm   
##  3   602      602   27.5 cm   
##  4   181      181   13.8 cm   
##  5   488      488   14.8 cm   
##  6   565      565   17   cm   
##  7   302      302   14.8 cm   
##  8    96       96   22.8 cm   
##  9   853      853   14.8 cm   
## 10   987      987   15.9 cm
\end{verbatim}

Since \texttt{sample\_n()} selects rows randomly, you will (very likely) get different set of 10 individuals/rows every single time. Below is another set of 10 rows (notice that \texttt{df\_i} is overwritten with the new data set):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_i }\OtherTok{\textless{}{-}}\NormalTok{ df\_h0 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{sample\_n}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{)}

\FunctionTok{print}\NormalTok{(df\_i)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 4
##     ...1 plant_id height unit 
##    <dbl>    <dbl>  <dbl> <chr>
##  1   962      962   19.9 cm   
##  2   618      618   11   cm   
##  3   614      614   13   cm   
##  4   735      735   22.1 cm   
##  5   215      215   24.9 cm   
##  6    32       32   19.5 cm   
##  7   230      230   21.3 cm   
##  8   367      367   23.4 cm   
##  9   270      270   15.3 cm   
## 10   524      524   21   cm
\end{verbatim}

Let's obtain 100 sets of 10 plant individuals (randomly selected) and \emph{estimate} the mean and variance in each. While we can perform random sampling one by one, this is cumbersome -- at least, I do not want to do it. Instead, we can leverage a technique of \texttt{for} loop:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for reproducibility}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{3}\NormalTok{)}

\NormalTok{mu\_i }\OtherTok{\textless{}{-}}\NormalTok{ var\_i }\OtherTok{\textless{}{-}} \ConstantTok{NULL} \CommentTok{\# create empty objects}

\CommentTok{\# repeat the work in \{\} from i = 1 to i = 100}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{100}\NormalTok{) \{}
  
\NormalTok{  df\_i }\OtherTok{\textless{}{-}}\NormalTok{ df\_h0 }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sample\_n}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{) }\CommentTok{\# random samples of 10 individuals}
  
  \CommentTok{\# save mean for sample set i}
\NormalTok{  mu\_i[i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(df\_i}\SpecialCharTok{$}\NormalTok{height)}
  
  \CommentTok{\# save variance for sample set i}
\NormalTok{  var\_i[i] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((df\_i}\SpecialCharTok{$}\NormalTok{height }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(df\_i}\SpecialCharTok{$}\NormalTok{height))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{nrow}\NormalTok{(df\_i) }
  
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Take a look at \texttt{mu\_i} and \texttt{var\_i} :

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(mu\_i)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [1] 19.97 17.86 22.55 22.03 17.00 23.28 21.33 21.23 18.55 19.29 22.14 19.84
##  [13] 22.43 22.13 21.13 19.40 19.39 20.43 19.12 20.66 21.01 19.48 21.73 19.63
##  [25] 21.03 20.60 21.11 20.42 18.76 23.70 20.31 22.22 21.34 20.70 20.96 20.03
##  [37] 21.77 19.19 19.87 21.38 19.64 23.31 19.89 19.21 19.68 19.54 17.54 19.05
##  [49] 18.91 20.57 18.33 18.07 19.48 17.70 20.24 17.74 20.45 16.48 18.93 17.60
##  [61] 17.23 20.75 18.06 20.06 20.80 21.72 19.02 25.08 18.90 20.69 23.28 20.87
##  [73] 18.65 19.74 21.47 17.95 16.98 18.30 19.77 17.25 19.60 21.27 19.28 20.42
##  [85] 19.60 18.41 20.15 21.24 19.70 21.56 20.75 19.54 17.54 18.52 19.85 18.40
##  [97] 20.39 17.07 17.84 20.66
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(var\_i)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [1] 14.1961 21.6884 28.2685 21.6341  6.5700 24.5996 23.6941 24.8681 21.6485
##  [10] 36.3689 17.8844 31.5784 21.0521 34.2341 20.6281 10.4420 20.0469 31.2781
##  [19] 32.0316 23.0964  9.8789 31.8916 28.3061 19.6861  8.2641 23.3640 26.8769
##  [28] 48.9416 27.7644 42.4220 38.4989 12.7076 15.9004  8.6740 11.7284 26.2061
##  [37] 21.7461 25.9269 28.0421  6.2616 16.5584 27.7489 17.3609 23.1349 38.6936
##  [46] 25.0984 13.5864 25.2625  7.7149 17.5341 11.4681 38.1561 12.6376 42.5480
##  [55] 31.9224 13.9824 14.9725 25.8296 33.6781  8.2440 31.4741 29.7805 26.7324
##  [64] 47.3704 26.8660 24.0536 29.5076 23.7376 14.8000 51.8449 13.3536 18.5581
##  [73] 18.9185 12.4544 36.2201 16.3225 17.9236 42.8760 18.5421 22.0205 34.1680
##  [82] 28.8841 26.6976 22.7356 35.2900 19.2229 34.3905 17.3784 23.1880 42.4264
##  [91] 18.5365 18.5424 21.5204 13.1276 17.7185 21.2940 27.1649 35.3141 43.5624
## [100] 55.1484
\end{verbatim}

In each element of \texttt{mu\_i} and \texttt{var\_i}, we have saved estimated mean (\(\hat{\mu}\); reads mu hat) and variance (\(\hat{\sigma^2}\)) of 10 plant height measures for dataset \texttt{i}. By drawing a histogram of these values, we can examine the distributions of mean and variance estimates. I use R package \texttt{patchwork} to make a better figure:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#install.packages("patchwork") \# install only once}
\FunctionTok{library}\NormalTok{(patchwork)}

\NormalTok{df\_sample }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{mu\_hat =}\NormalTok{ mu\_i, }\AttributeTok{var\_hat =}\NormalTok{ var\_i)}

\CommentTok{\# histogram for mean}
\NormalTok{g\_mu }\OtherTok{\textless{}{-}}\NormalTok{ df\_sample }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mu\_hat)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ mu)}

\CommentTok{\# histogram for variance}
\NormalTok{g\_var }\OtherTok{\textless{}{-}}\NormalTok{ df\_sample }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ var\_hat)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ sigma2)}

\CommentTok{\# layout vertically}
\CommentTok{\# possible only if "patchwork" is loaded}
\NormalTok{g\_mu }\SpecialCharTok{/}\NormalTok{ g\_var}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{_main_files/figure-latex/mu-var-dist-1} \end{center}

While sample means are indeed symmetrically distributed around the true mean, sample variances tend to be biased and skewed to the right, often underestimating the true variance.

The bias in estimating the variance arises due to inferring the parameter from a small number of samples. However, there is good news: an unbiased estimator of variance exists. The formula for the unbiased estimator of variance is as follows:

\[
\frac{\sum_i^N (x_i - \mu)^2}{N-1}
\]

The correction in the denominator (\(N\) replaced with \(N-1\)) compensates for the bias, providing an estimate of the true variance without systematic underestimation (although this seems a simple correction, a \href{https://en.wikipedia.org/wiki/Bessel\%27s_correction}{deep math} underlies the derivation of \(N-1\)). This is the default formula in \texttt{var()} in R, a function used to estimate \emph{unbiased} variance (and \emph{unbiased} SD \texttt{sd()}). Comparison reveals how this works:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for reproducibility}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{3}\NormalTok{)}

\CommentTok{\# redo simulations {-}{-}{-}{-}}
\NormalTok{mu\_i }\OtherTok{\textless{}{-}}\NormalTok{ var\_i }\OtherTok{\textless{}{-}}\NormalTok{ var\_ub\_i }\OtherTok{\textless{}{-}} \ConstantTok{NULL} \CommentTok{\# create empty objects}

\CommentTok{\# repeat the work in \{\} from i = 1 to i = 100}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{100}\NormalTok{) \{}
  
\NormalTok{  df\_i }\OtherTok{\textless{}{-}}\NormalTok{ df\_h0 }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sample\_n}\NormalTok{(}\AttributeTok{size =} \DecValTok{10}\NormalTok{) }\CommentTok{\# random samples of 10 individuals}
  
  \CommentTok{\# save mean for sample set i}
\NormalTok{  mu\_i[i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(df\_i}\SpecialCharTok{$}\NormalTok{height)}
  
  \CommentTok{\# save variance for sample set i}
\NormalTok{  var\_i[i] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((df\_i}\SpecialCharTok{$}\NormalTok{height }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(df\_i}\SpecialCharTok{$}\NormalTok{height))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{nrow}\NormalTok{(df\_i) }
  
\NormalTok{  var\_ub\_i[i] }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(df\_i}\SpecialCharTok{$}\NormalTok{height)}
\NormalTok{\}}

\CommentTok{\# draw histograms {-}{-}{-}{-}}
\NormalTok{df\_sample }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{mu\_hat =}\NormalTok{ mu\_i,}
                    \AttributeTok{var\_hat =}\NormalTok{ var\_i,}
                    \AttributeTok{var\_ub\_hat =}\NormalTok{ var\_ub\_i)}

\CommentTok{\# histogram for mu}
\NormalTok{g\_mu }\OtherTok{\textless{}{-}}\NormalTok{ df\_sample }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mu\_hat)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ mu)}

\CommentTok{\# histogram for variance}
\CommentTok{\# scale\_x\_continuous() adjusts scale in x{-}axis}
\NormalTok{g\_var }\OtherTok{\textless{}{-}}\NormalTok{ df\_sample }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ var\_hat)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ sigma2) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{limits=} \FunctionTok{c}\NormalTok{(}\FunctionTok{min}\NormalTok{(var\_i, var\_ub\_i),}
                               \FunctionTok{max}\NormalTok{(var\_i, var\_ub\_i)))}

\CommentTok{\# histogram for unbiased variance}
\NormalTok{g\_var\_ub }\OtherTok{\textless{}{-}}\NormalTok{ df\_sample }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ var\_ub\_hat)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ sigma2) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{limits=} \FunctionTok{c}\NormalTok{(}\FunctionTok{min}\NormalTok{(var\_i, var\_ub\_i),}
                               \FunctionTok{max}\NormalTok{(var\_i, var\_ub\_i)))}

\NormalTok{g\_mu }\SpecialCharTok{/}\NormalTok{ g\_var }\SpecialCharTok{/}\NormalTok{ g\_var\_ub}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{_main_files/figure-latex/var-ub-1} \end{center}

In summary, samples can only provide information about a part of the whole population. The complete picture of the entire population is often unknown, and we rely on estimating key parameters from the available samples. This concept applies to a wide range of parametric analyses in statistics, where we use sample data to make inferences about the population parameters.

Recognizing the limitations and uncertainties associated with working with samples is essential for proper statistical analysis and interpretation of results in various fields of study.

\hypertarget{laboratory-1}{%
\section{Laboratory}\label{laboratory-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  We used 10 plants to estimate sample means and variances. Obtain 100 sub-datasets with 50 and 100 measures each, and draw histograms of sample means and unbiased variances (use \texttt{var()}).
\item
  Sample means and unbiased variances are unbiased if samples are randomly selected. What happens if samples are non-random? Suppose the investigator was unable to find plants less than 10 cm in height -- the following code excludes those less than 10 cm in height:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_h10 }\OtherTok{\textless{}{-}}\NormalTok{ df\_h0 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(height }\SpecialCharTok{\textgreater{}=} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

  Repeat step 1 with \texttt{df\_h10} instead of \texttt{df\_h0} and compare the results.
\end{enumerate}

\hypertarget{probabilistic-view}{%
\chapter{Probabilistic View}\label{probabilistic-view}}

Chapter \ref{sampling} emphasized the concept of sampling and introduced the crucial aspect of statistics: randomness. Although the mean represents the central tendency of the data, it does not encompass all the data points. Inevitable deviations occur, and we need a way to express this ``randomness.'' The concept of probability distributions aids in fully understanding the stochastic nature of observed data.

\hypertarget{probability-distribution-of-a-continuous-variable}{%
\section{Probability Distribution of a Continuous Variable}\label{probability-distribution-of-a-continuous-variable}}

\hypertarget{probability-density-function}{%
\subsection{Probability Density Function}\label{probability-density-function}}

Let me use the plant height example in Chapter \ref{sampling}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load csv data on R}
\NormalTok{df\_h0 }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data\_raw/data\_plant\_height.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

While Chapter \ref{sampling} primarily focused on exploring mean and variance, let's broaden our perspective to gain a comprehensive understanding of the entire distribution of height.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_h0 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ height)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# specify binwidth}
  \FunctionTok{geom\_vline}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept =} \FunctionTok{mean}\NormalTok{(height))) }\CommentTok{\# draw vertical line at the mean}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{_main_files/figure-latex/histogram-height-1} 

}

\caption{Distribution of plant height}\label{fig:histogram-height}
\end{figure}

This distribution comprises a thousand height measurements. However, there are certain patterns to consider. The data is centered around the mean and exhibits a symmetrical distribution. This characteristic implies that the distribution can be approximated by a simple formula that relies on only a few \emph{key parameters}.

In statistics, the symmetrical bell-shaped form is commonly approximated by a Normal distribution, often denoted as ``\emph{variable} \(x\) \emph{is assumed to follow a Normal distribution.}'' We express this using the following mathematical expression:

\[
x \sim Normal(\mu, \sigma^2)
\]

Unlike an ``equation,'' we do not use the ``\(=\)'' sign because variable \(x\) is not equivalent to the Normal distribution. Rather, it represents a ``stochastic'' relationship that signifies the probability of \(x\) taking on a specific range of values.

A Normal distribution is characterized by two parameters: the mean and the variance. Once these parameters are determined, the formula that defines the Normal distribution will yield the probability density for a given range of values. This formula \(f(x)\) is known as the \textbf{probability density function (PDF)} and is displayed below:

\[
f(x) = \frac{1}{\sqrt{2 \pi} \sigma} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
\]

\hypertarget{pdf-to-frequency-distribution}{%
\subsection{PDF to frequency distribution}\label{pdf-to-frequency-distribution}}

In R, the function \texttt{dnorm()} can be used to calculate the probability density for a given value. The first argument, \texttt{x}, should be a vector of values for which you want to calculate the probability density. The second argument, \texttt{mean}, and the third argument, \texttt{sd}, correspond to the mean and standard deviation of the distribution, respectively. Note that we must provide \texttt{mean} and \texttt{sd} to calculate the probability density.

To encompass the entire range of observed heights, we can use \(\text{min}(x)\) and \(\text{max}(x)\) as the lower and upper limits, respectively.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# vector of x values}
\CommentTok{\# seq() generate min to max values with specified numbers of elements or interval}
\CommentTok{\# the following produce 100 elements}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(df\_h0}\SpecialCharTok{$}\NormalTok{height), }\FunctionTok{max}\NormalTok{(df\_h0}\SpecialCharTok{$}\NormalTok{height), }\AttributeTok{length =} \DecValTok{100}\NormalTok{)}

\CommentTok{\# calculate probability density}
\NormalTok{mu }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(df\_h0}\SpecialCharTok{$}\NormalTok{height)}
\NormalTok{sigma }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(df\_h0}\SpecialCharTok{$}\NormalTok{height)}
\NormalTok{pd }\OtherTok{\textless{}{-}} \FunctionTok{dnorm}\NormalTok{(x, }\AttributeTok{mean =}\NormalTok{ mu, }\AttributeTok{sd =}\NormalTok{ sigma)}

\CommentTok{\# figure}
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{y =}\NormalTok{ pd, }\AttributeTok{x =}\NormalTok{ x) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# data frame}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+} \CommentTok{\# draw lines}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Probability density"}\NormalTok{) }\CommentTok{\# re{-}label}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{_main_files/figure-latex/dnorm-1} 

}

\caption{Probability density function of a Normal distribution}\label{fig:dnorm}
\end{figure}

The shape of the curve appears quite similar to what we observed; however, the scale of the y-axis is different. This is because the y-axis represents ``probability density.'' To convert it into actual ``probability,'' we need to calculate the area under the curve. In R, we can utilize the \texttt{pnorm()} function for this purpose. It calculates the probability of a variable being less than the specified value, which is provided in the first argument \texttt{q}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# probability of x \textless{} 10}
\NormalTok{p10 }\OtherTok{\textless{}{-}} \FunctionTok{pnorm}\NormalTok{(}\AttributeTok{q =} \DecValTok{10}\NormalTok{, }\AttributeTok{mean =}\NormalTok{ mu, }\AttributeTok{sd =}\NormalTok{ sigma)}
\FunctionTok{print}\NormalTok{(p10)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.02731905
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# probability of x \textless{} 20}
\NormalTok{p20 }\OtherTok{\textless{}{-}} \FunctionTok{pnorm}\NormalTok{(}\AttributeTok{q =} \DecValTok{20}\NormalTok{, }\AttributeTok{mean =}\NormalTok{ mu, }\AttributeTok{sd =}\NormalTok{ sigma)}
\FunctionTok{print}\NormalTok{(p20)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.504426
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# probability of 10 \textless{} x \textless{} 20}
\NormalTok{p20\_10 }\OtherTok{\textless{}{-}}\NormalTok{ p20 }\SpecialCharTok{{-}}\NormalTok{ p10}
\FunctionTok{print}\NormalTok{(p20\_10)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4771069
\end{verbatim}

To make the estimates comparable to the frequency data, you can calculate the probability for each 1 cm bin. The expected frequency can be obtained by multiplying the probability by the sample size, which in this case is 1000. This allows you to estimate the number of observations you would expect in each 1 cm bin based on the calculated probabilities.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x\_min }\OtherTok{\textless{}{-}} \FunctionTok{floor}\NormalTok{(}\FunctionTok{min}\NormalTok{(df\_h0}\SpecialCharTok{$}\NormalTok{height)) }\CommentTok{\# floor takes the integer part of the value}
\NormalTok{x\_max }\OtherTok{\textless{}{-}} \FunctionTok{ceiling}\NormalTok{(}\FunctionTok{max}\NormalTok{(df\_h0}\SpecialCharTok{$}\NormalTok{height)) }\CommentTok{\# ceiling takes the next closest integer}
\NormalTok{bin }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(x\_min, x\_max, }\AttributeTok{by =} \DecValTok{1}\NormalTok{) }\CommentTok{\# each bin has 1cm}

\NormalTok{p }\OtherTok{\textless{}{-}} \ConstantTok{NULL} \CommentTok{\# empty object for probability}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{(}\FunctionTok{length}\NormalTok{(bin) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) \{}
\NormalTok{  p[i] }\OtherTok{\textless{}{-}} \FunctionTok{pnorm}\NormalTok{(bin[i}\SpecialCharTok{+}\DecValTok{1}\NormalTok{], }\AttributeTok{mean =}\NormalTok{ mu, }\AttributeTok{sd =}\NormalTok{ sigma) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(bin[i], }\AttributeTok{mean =}\NormalTok{ mu, }\AttributeTok{sd =}\NormalTok{ sigma)}
\NormalTok{\}}

\CommentTok{\# data frame for probability}
\CommentTok{\# bin: last element [{-}length(bin)] was removed to match length}
\CommentTok{\# expected frequency in each bin is "prob times sample size"}
\NormalTok{df\_prob }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(p, }\AttributeTok{bin =}\NormalTok{ bin[}\SpecialCharTok{{-}}\FunctionTok{length}\NormalTok{(bin)]) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{freq =}\NormalTok{ p }\SpecialCharTok{*} \FunctionTok{nrow}\NormalTok{(df\_h0))}
\end{Highlighting}
\end{Shaded}

Overlay:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_h0 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ height)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df\_prob,}
             \FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ freq,}
                 \AttributeTok{x =}\NormalTok{ bin),}
             \AttributeTok{color =} \StringTok{"salmon"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df\_prob,}
            \FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ freq,}
                \AttributeTok{x =}\NormalTok{ bin),}
            \AttributeTok{color =} \StringTok{"salmon"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{_main_files/figure-latex/histogram-overlaid-1} 

}

\caption{Histogram overlaid with predicted frequency (red dots and line)}\label{fig:histogram-overlaid}
\end{figure}

It is remarkable that the probability distribution, characterized by just two parameters (mean and variance), can effectively reproduce the overall shape observed in the original data set of 1000 data points. This is great news because it means that once we determine these key parameters, we can infer the general pattern of the data.

\hypertarget{probability-distribution-of-a-discrete-variable}{%
\section{Probability Distribution of a Discrete Variable}\label{probability-distribution-of-a-discrete-variable}}

\hypertarget{probability-mass-function}{%
\subsection{Probability Mass Function}\label{probability-mass-function}}

Let's shift our perspective and examine the density of plants in the garden. For this analysis, we have counted the number of plant individuals within 30 plots, with each plot covering an area of one square meter (refer to Figure \ref{fig:garden}).

\begin{figure}

{\centering \includegraphics[width=16.67in]{image/figure_garden} 

}

\caption{Garden view with sampling plots. White squares represent plots. Red dots indicate plant individuals counted.}\label{fig:garden}
\end{figure}

Download the data \href{https://github.com/aterui/biostats/blob/master/data_raw/data_garden_count.csv}{here} and load it onto R:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_count }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data\_raw/data\_garden\_count.csv"}\NormalTok{)}
\FunctionTok{print}\NormalTok{(df\_count)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 30 x 2
##     plot count
##    <dbl> <dbl>
##  1     1     3
##  2     2     2
##  3     3     3
##  4     4     1
##  5     5     2
##  6     6     1
##  7     7     3
##  8     8     3
##  9     9     3
## 10    10     1
## # i 20 more rows
\end{verbatim}

Make a histogram:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_count }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ count)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \FloatTok{0.5}\NormalTok{, }\CommentTok{\# define binwidth}
                 \AttributeTok{center =} \DecValTok{0}\NormalTok{) }\CommentTok{\# relative position of each bin}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{_main_files/figure-latex/hist-density-1} 

}

\caption{Histogram of plant individuals per plot}\label{fig:hist-density}
\end{figure}

There are several significant differences compared to the plant height example when considering the density of plants in the garden:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The possible values are discrete (count data) since we are counting the number of plant individuals in each plot.
\item
  The possible values are always positive, as counts cannot be negative.
\item
  The distribution appears to be non-symmetric around the sample mean.
\end{enumerate}

Given these characteristics, a Normal distribution may not be an appropriate choice for representing such a variable. Instead, it would be more suitable to use a Poisson distribution to characterize the observed distribution of the discrete variable.

\[
x \sim Poisson(\lambda)
\]

In a Poisson distribution, the mean parameter (\(\lambda\)) serves as the sole parameter\footnote{In a Poisson distribution, mean = variance}. Probability distributions that describe discrete variables are expressed using a \textbf{probability mass function} (PMF):

\[
g(x) = \frac{\lambda^x \exp(-\lambda)}{x!}
\]

Unlike a probability density function (PDF), a probability mass function (PMF) represents the probability of a discrete variable \(x\) taking a specific value. For instance, the probability of \(x=2\), denoted as \(\Pr(x=2)\), can be calculated as follows:

\[
\Pr(x=2) = g(2) = \frac{\lambda^2 \exp(-\lambda)}{2!}
\]

In a generalized form, we write:

\[
\Pr(x=k) = g(k) = \frac{\lambda^k \exp(-\lambda)}{k!}
\]

\hypertarget{pmf-to-frequency-distribution}{%
\subsection{PMF to frequency distribution}\label{pmf-to-frequency-distribution}}

In R, you can use the \texttt{dpois()} function to visualize a Poisson distribution. This function allows you to plot the probability mass function (PMF) of the Poisson distribution and gain insights into the distribution of the discrete variable.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# vector of x values}
\CommentTok{\# create a vector of 0 to 10 with an interval one}
\CommentTok{\# must be integer of \textgreater{} 0}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\AttributeTok{by =} \DecValTok{1}\NormalTok{)}

\CommentTok{\# calculate probability mass}
\NormalTok{lambda\_hat }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(df\_count}\SpecialCharTok{$}\NormalTok{count)}
\NormalTok{pm }\OtherTok{\textless{}{-}} \FunctionTok{dpois}\NormalTok{(x, }\AttributeTok{lambda =}\NormalTok{ lambda\_hat)}

\CommentTok{\# figure}
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{y =}\NormalTok{ pm, }\AttributeTok{x =}\NormalTok{ x) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# data frame}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# draw dashed lines}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+} \CommentTok{\# draw points}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Probability"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Count"}\NormalTok{) }\CommentTok{\# re{-}label}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{_main_files/figure-latex/dpois-1} 

}

\caption{Example of a Poisson distribution}\label{fig:dpois}
\end{figure}

To convert the y-axis from probability to frequency, multiply the probabilities by the sample size (total number of observations) to obtain the expected frequency. As in the plant height example, you can plot the expected frequency on the histogram, providing a visual representation of the distribution of the discrete variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_prob }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ pm) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{freq =}\NormalTok{ y }\SpecialCharTok{*} \FunctionTok{nrow}\NormalTok{(df\_count)) }\CommentTok{\# prob x sample size}

\NormalTok{df\_count }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ count)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \FloatTok{0.5}\NormalTok{,}
                 \AttributeTok{center =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df\_prob,}
            \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x,}
                \AttributeTok{y =}\NormalTok{ freq),}
            \AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df\_prob,}
             \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x,}
                \AttributeTok{y =}\NormalTok{ freq))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{_main_files/figure-latex/pois-hist-1} 

}

\caption{Observed histogram of the discrete variable overlaid with the Poisson expectation.}\label{fig:pois-hist}
\end{figure}

Cool, the Poisson distribution does an excellent job of characterizing the distribution of plant counts.

\hypertarget{why-probability-distributions}{%
\section{Why Probability Distributions?}\label{why-probability-distributions}}

As we have seen in the above examples, probability distributions provide a framework for describing the likelihood of different outcomes or events. By utilizing probability distributions, we can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Make predictions and estimate probabilities of specific events or ranges of values.
\item
  Determine the most likely values or outcomes based on available information.
\item
  Quantify and analyze the uncertainty associated with random variables or processes.
\end{enumerate}

Probability distributions serve as fundamental tools in statistics, enabling us to model, analyze, and make informed decisions in the face of uncertainty.

\hypertarget{laboratory-2}{%
\section{Laboratory}\label{laboratory-2}}

\hypertarget{normal-distribution}{%
\subsection{Normal Distribution}\label{normal-distribution}}

The function \texttt{rnorm()} produces a random variable that follows a Normal distribution with a specified mean and SD. Using this function,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Generate a variable with 50 observations.
\item
  Create a figure similar to Figure \ref{fig:histogram-overlaid}
\end{enumerate}

\hypertarget{poisson-distribution}{%
\subsection{Poisson Distribution}\label{poisson-distribution}}

The function \texttt{rpois()} produces a random variable that follows a Poisson distribution with a specified mean. Using this function,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Generate a variable with 1000 observations.
\item
  Create a figure similar to Figure \ref{fig:pois-hist}
\end{enumerate}

\hypertarget{two-group-comparison}{%
\chapter{Two-Group Comparison}\label{two-group-comparison}}

Data consists of ``samples'' extracted from the population of interest, but it's important to acknowledge that these samples are not flawless replicas of the entire population. Given this imperfect information, how can we effectively investigate and discern the distinction between two populations? In this Chapter, I will introduce one of the most basic statistical tests -- ``t-test.'' The t-test takes the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define a \textbf{test statistic} to signify the difference between groups (t-statistic).
\item
  Define a probability distribution of t-statistic under the \textbf{null hypothesis}, i.e., a scenario that we assume no difference between groups.
\item
  Estimate the probability of yielding greater or less than the observed test statistic.
\end{enumerate}

\hypertarget{explore-data-structure}{%
\section{Explore Data Structure}\label{explore-data-structure}}

Suppose that we study fish populations of the same species in two lakes (Lake \texttt{a} and \texttt{b}). These lakes are in stark contrast of productivity (Lake \texttt{b} looks more productive), and our interest is the difference in \emph{mean} body size between the two lakes. We obtained \(50\) data points of fish length from each lake (download \href{https://github.com/aterui/biostats/blob/master/data_raw/data_fish_length.csv}{here}). Save under \texttt{data\_raw/} and use \texttt{read\_csv()} to read data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse) }\CommentTok{\# call add{-}in packages everytime you open new R session}
\NormalTok{df\_fl }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data\_raw/data\_fish\_length.csv"}\NormalTok{)}
\FunctionTok{print}\NormalTok{(df\_fl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 100 x 3
##    lake  length unit 
##    <chr>  <dbl> <chr>
##  1 a       10.8 cm   
##  2 a       13.6 cm   
##  3 a       10.1 cm   
##  4 a       18.6 cm   
##  5 a       14.2 cm   
##  6 a       10.1 cm   
##  7 a       14.7 cm   
##  8 a       15.6 cm   
##  9 a       15   cm   
## 10 a       11.9 cm   
## # i 90 more rows
\end{verbatim}

In this data frame, fish length data from lake \texttt{a} and \texttt{b} are recorded. Confirm this with \texttt{unique()} or \texttt{distinct()} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# unique returns unique values as a vector}
\FunctionTok{unique}\NormalTok{(df\_fl}\SpecialCharTok{$}\NormalTok{lake)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "a" "b"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# distinct returns unique values as a tibble}
\FunctionTok{distinct}\NormalTok{(df\_fl, lake)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 1
##   lake 
##   <chr>
## 1 a    
## 2 b
\end{verbatim}

Visualization provides a powerful tool for summarizing data effectively. By plotting individual data points overlaid with mean values and error bars, we can observe the distribution and patterns within the data, allowing us to identify trends, variations, and potential outliers:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# group mean and sd}
\NormalTok{df\_fl\_mu }\OtherTok{\textless{}{-}}\NormalTok{ df\_fl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(lake) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# group operation}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mu\_l =} \FunctionTok{mean}\NormalTok{(length), }\CommentTok{\# summarize by mean()}
            \AttributeTok{sd\_l =} \FunctionTok{sd}\NormalTok{(length)) }\CommentTok{\# summarize with sd()}

\CommentTok{\# plot}
\CommentTok{\# geom\_jitter() plot data points with scatter}
\CommentTok{\# geom\_segment() draw lines}
\CommentTok{\# geom\_point() draw points}
\NormalTok{df\_fl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ lake,}
             \AttributeTok{y =}\NormalTok{ length)) }\SpecialCharTok{+}
  \FunctionTok{geom\_jitter}\NormalTok{(}\AttributeTok{width =} \FloatTok{0.1}\NormalTok{, }\CommentTok{\# scatter width}
              \AttributeTok{height =} \DecValTok{0}\NormalTok{, }\CommentTok{\# scatter height (no scatter with zero)}
              \AttributeTok{alpha =} \FloatTok{0.25}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# transparency of data points}
  \FunctionTok{geom\_segment}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df\_fl\_mu, }\CommentTok{\# switch data frame}
               \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ lake,}
                   \AttributeTok{xend =}\NormalTok{ lake,}
                   \AttributeTok{y =}\NormalTok{ mu\_l }\SpecialCharTok{{-}}\NormalTok{ sd\_l,}
                   \AttributeTok{yend =}\NormalTok{ mu\_l }\SpecialCharTok{+}\NormalTok{ sd\_l)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df\_fl\_mu, }\CommentTok{\# switch data frame}
             \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ lake,}
                 \AttributeTok{y =}\NormalTok{ mu\_l),}
             \AttributeTok{size =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Lake"}\NormalTok{, }\CommentTok{\# x label}
       \AttributeTok{y =} \StringTok{"Fish body length"}\NormalTok{) }\CommentTok{\# y label}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{_main_files/figure-latex/mean-plot-1} 

}

\caption{Example of mean and SD plot}\label{fig:mean-plot}
\end{figure}

Hmm, it is possible that there is a noticeable disparity in body size between Lake \texttt{a} and Lake \texttt{b}. However, how can we ascertain and provide evidence for this claim?

\hypertarget{test-statistic}{%
\section{Test Statistic}\label{test-statistic}}

\hypertarget{t-statistic}{%
\subsection{t-statistic}\label{t-statistic}}

Since our focus is on examining the difference in means, it is logical to estimate the disparity between the sample means in each lake. Let me denote the sample means as \(\hat{\mu}_a\) and \(\hat{\mu}_b\) for Lake \texttt{a} and Lake \texttt{b}, respectively. We can estimate the difference between the means using the following approach:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# take another look at df\_fl\_mu}
\FunctionTok{print}\NormalTok{(df\_fl\_mu)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##   lake   mu_l  sd_l
##   <chr> <dbl> <dbl>
## 1 a      13.4  2.92
## 2 b      15.4  3.39
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# pull mu\_l from tibble as vector}
\NormalTok{v\_mu }\OtherTok{\textless{}{-}}\NormalTok{ df\_fl\_mu }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pull}\NormalTok{(mu\_l)}

\CommentTok{\# lake a}
\FunctionTok{print}\NormalTok{(v\_mu[}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 13.35
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# lake b}
\FunctionTok{print}\NormalTok{(v\_mu[}\DecValTok{2}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.406
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# difference}
\NormalTok{v\_mu[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ v\_mu[}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -2.056
\end{verbatim}

The average fish body size in Lake \texttt{b} is approximately 2 cm larger than that in Lake \texttt{a}. However, it is crucial to recognize that we are still lacking vital information, specifically, the uncertainty associated with this difference. As discussed in Chapter \ref{sampling}, we must acknowledge that sample means are not flawless representations of the entire population.

Fortunately, we can utilize sample variances to address such uncertainties. The \textbf{t-statistic} is a common indicator of the difference of means that takes into consideration the uncertainty associated with sample means.

\[
t = \frac{\hat{\mu_a} - \hat{\mu_b}}{\sqrt{\hat{\sigma}^2_p \left(\frac{1}{N_a} + \frac{1}{N_b}\right)}}
\]

where \(N_a\) and \(N_b\) are sample sizes in Lake \texttt{a} and \texttt{b} (i.e., \(N_a = N_b = 50\) in this specific example), and \(\hat{\sigma}^2_p\) is the weighted mean of sample variances:

\[
\hat{\sigma}^2_p = \frac{N_a-1}{N_a + N_b - 2}\hat{\sigma}^2_a + \frac{N_b-1}{N_a + N_b - 2}\hat{\sigma}^2_b
\]

We can calculate this value in R manually:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# group mean, variance, and sample size}
\NormalTok{df\_t }\OtherTok{\textless{}{-}}\NormalTok{ df\_fl }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(lake) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# group operation}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mu\_l =} \FunctionTok{mean}\NormalTok{(length), }\CommentTok{\# summarize by mean()}
            \AttributeTok{var\_l =} \FunctionTok{var}\NormalTok{(length), }\CommentTok{\# summarize with sd()}
            \AttributeTok{n =} \FunctionTok{n}\NormalTok{()) }\CommentTok{\# count number of rows per group}

\FunctionTok{print}\NormalTok{(df\_t)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 4
##   lake   mu_l var_l     n
##   <chr> <dbl> <dbl> <int>
## 1 a      13.4  8.52    50
## 2 b      15.4 11.5     50
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# pull values as a vector}
\NormalTok{v\_mu }\OtherTok{\textless{}{-}} \FunctionTok{pull}\NormalTok{(df\_t, mu\_l)}
\NormalTok{v\_var }\OtherTok{\textless{}{-}} \FunctionTok{pull}\NormalTok{(df\_t, var\_l)}
\NormalTok{v\_n }\OtherTok{\textless{}{-}} \FunctionTok{pull}\NormalTok{(df\_t, n)}

\NormalTok{var\_p }\OtherTok{\textless{}{-}}\NormalTok{ ((v\_n[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{sum}\NormalTok{(v\_n) }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{*}\NormalTok{ v\_var[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}
\NormalTok{  ((v\_n[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{sum}\NormalTok{(v\_n) }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{*}\NormalTok{ v\_var[}\DecValTok{2}\NormalTok{]}

\NormalTok{t\_value }\OtherTok{\textless{}{-}}\NormalTok{ (v\_mu[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ v\_mu[}\DecValTok{2}\NormalTok{]) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(var\_p }\SpecialCharTok{*}\NormalTok{ ((}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ v\_n[}\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ v\_n[}\DecValTok{2}\NormalTok{])))}

\FunctionTok{print}\NormalTok{(t\_value)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -3.247322
\end{verbatim}

The difference in sample means were -2.06; therefore, t-statistic further emphasizes the distinction between the study lakes. This occurrence can be attributed to the t-statistic formula.

In the denominator, we observe the inclusion of \(\hat{\sigma}^2_p\) (estimated pooled variance), as well as the inverses of sample sizes \(N_a\) and \(N_b\). Consequently, as \(\hat{\sigma}^2_p\) decreases and/or the sample sizes increase, the t-statistic increases. This is a reasonable outcome since a decrease in variance and/or an increase in sample size enhance the certainty of the mean difference.

\hypertarget{null-hypothesis}{%
\subsection{Null Hypothesis}\label{null-hypothesis}}

The observed t-statistic serves a dual purpose in accounting for both the disparity of means and the accompanying uncertainty. However, the significance of this t-statistic remains unclear.

To address this, the concept of the \textbf{Null Hypothesis} is utilized to substantiate the observed t-statistic. The Null Hypothesis, no difference between groups or \(\mu_a = \mu_b\), allows us to draw the probability distribution of the test-statistic. Once we know the probability distribution, we can \textbf{\emph{estimate the probability of observing the given t-statistic by random chance}} if there were no difference in mean body size between the lakes.

Let's begin by assuming that there is no difference in the mean body size of fish populations between the lakes, meaning the true difference in means is zero (\(\mu_a - \mu_b = 0\); without hats in this formula!). Under this assumption, we can define the probability distribution of t-statistics, which represents how t-statistics are distributed across a range of possible values.

This probability distribution is known as the Student's t-distribution and is characterized by three parameters: the mean, the variance, and the degrees of freedom (d.f.). Considering that we are evaluating the difference in body size as the test statistic, the mean (of the difference) is assumed to be zero. The variance is estimated using \(\hat{\sigma}^2_p\), and the degrees of freedom are determined by \(N_a + N_b - 2\) (where d.f. can be considered as a measure related to the sample size\footnote{Discussing the concept of degrees of freedom in depth would require a more comprehensive explanation, so I will refer to it here as a quantity relevant to the sample size.}).

R has a function to draw the Student's t-distribution; let's try that out:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# produce 500 values from {-}5 to 5 with equal interval}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\AttributeTok{length =} \DecValTok{500}\NormalTok{)}

\CommentTok{\# probability density of t{-}statistics with df = sum(v\_n) {-} 2}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{dt}\NormalTok{(x, }\AttributeTok{df =} \FunctionTok{sum}\NormalTok{(v\_n) }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)}

\CommentTok{\# draw figure}
\FunctionTok{tibble}\NormalTok{(x, y) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x,}
             \AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Probability density"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"t{-}statistic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{_main_files/figure-latex/student-t-1} 

}

\caption{Distribution of t-statistics under null hypothesis. The probability density in a distribution determines the likelihood of observing a particular t-statistic. Higher probability density indicates a greater likelihood of the t-statistic occurring.}\label{fig:student-t}
\end{figure}

The probability density in a distribution (Figure \ref{fig:student-t}) determines the likelihood of observing a particular t-statistic. Higher probability density indicates a greater likelihood of the t-statistic occurring. Compare the observed t-statistic against this null distribution:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# draw entire range}
\FunctionTok{tibble}\NormalTok{(x, y) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x,}
             \AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ t\_value,}
             \AttributeTok{color =} \StringTok{"salmon"}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# t\_value is the observed t\_value}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \FunctionTok{abs}\NormalTok{(t\_value),}
             \AttributeTok{color =} \StringTok{"salmon"}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# t\_value is the observed t\_value}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Probability density"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"t{-}statistic"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{_main_files/figure-latex/student-t-obs-1} 

}

\caption{Observed t-statistic in comparison to the null distrubution}\label{fig:student-t-obs}
\end{figure}

In a probability distribution, the area under the curve corresponds to the probability. Notably, \textbf{the area under the curve that falls below or above the observed t-statistic (indicated by vertical red lines) is very small (Figure} \ref{fig:student-t-obs}\textbf{)}, meaning that the observed difference in body size is very unlikely to occur under the null hypothesis (no difference in true means).

The function \texttt{pt()} allows us to calculate the area under the curve:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate area under the curve from {-}infinity to t\_value}
\NormalTok{pr\_below }\OtherTok{\textless{}{-}} \FunctionTok{pt}\NormalTok{(}\AttributeTok{q =}\NormalTok{ t\_value, }\AttributeTok{df =} \FunctionTok{sum}\NormalTok{(v\_n) }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)}

\CommentTok{\# calculate area under the curve from abs(t\_value) to infinity}
\NormalTok{pr\_above }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pt}\NormalTok{(}\AttributeTok{q =} \FunctionTok{abs}\NormalTok{(t\_value), }\AttributeTok{df =} \FunctionTok{sum}\NormalTok{(v\_n) }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \textbf{p-value,} i.e., \emph{the probability of observing t-statistics} less than ( \texttt{pr\_below}) or greater than (\texttt{pr\_above}) the observed t-statistic under the null hypothesis, can be estimated as the sum of \texttt{pr\_below} and \texttt{pr\_above}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# p\_value}
\NormalTok{p\_value }\OtherTok{\textless{}{-}}\NormalTok{ pr\_below }\SpecialCharTok{+}\NormalTok{ pr\_above}
\FunctionTok{print}\NormalTok{(p\_value)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.001595529
\end{verbatim}

\hypertarget{interpretation}{%
\subsection{Interpretation}\label{interpretation}}

The above exercise is called \textbf{t-test} -- perhaps, the most well-known hypothesis testing. To explain the interpretation of the results, let me use the following notations. \(t_{obs}\), the observed t-statistic; \(t_0\), possible t-statistics under the null hypothesis; \(\Pr(\cdot)\), the probability of ``\(\cdot\)'' occurs -- for example, \(\Pr(x > 2)\) means that the probability of \(x\) exceeding \(2\).

We first calculated the observed t-statistic \(t_{obs}\) using the data of fish body size, which was -3.25. Then, we calculated p-value, i.e., \(\Pr(t_0 < t_{obs}) + \Pr(t_0 > t_{obs})\) under the null hypothesis of \(\mu_a = \mu_b\). We found p-value was very low, meaning that the observed t-statistic is very unlikely to occur if \(\mu_a = \mu_b\) is the truth. Therefore, it is logical to conclude that the \textbf{Alternative Hypothesis} \(\mu_a \ne \mu_b\) is very likely.

The same logic is used in many statistical analyses -- define the null hypothesis, and estimate the probability of observing a given value under the null hypothesis. It is tricky, but I find this genius: we can substantiate the observation(s) objectively that are otherwise a subjective claim!

However, it is crucial to recognize that, \textbf{even if we found the observed t-statistic that results in very high p-value (i.e., very common under the null hypothesis), finding such a result does NOT support the null hypothesis -- we just can't reject it.}

\hypertarget{t-test-in-r}{%
\section{t-test in R}\label{t-test-in-r}}

\hypertarget{t-test-with-equal-variance}{%
\subsection{t-test with equal variance}\label{t-test-with-equal-variance}}

In R, this t-test can be performed with \texttt{t.test()}. Let me examine if the function gives us identical results:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ df\_fl }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(lake }\SpecialCharTok{==} \StringTok{"a"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}  \CommentTok{\# subset lake a}
  \FunctionTok{pull}\NormalTok{(length)}

\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ df\_fl }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(lake }\SpecialCharTok{==} \StringTok{"b"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# subset lake b}
  \FunctionTok{pull}\NormalTok{(length)}

\FunctionTok{t.test}\NormalTok{(x, y, }\AttributeTok{var.equal =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Two Sample t-test
## 
## data:  x and y
## t = -3.2473, df = 98, p-value = 0.001596
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -3.3124399 -0.7995601
## sample estimates:
## mean of x mean of y 
##    13.350    15.406
\end{verbatim}

The reported t-statistic \texttt{t\ =\ -3.2473}, the p-value \texttt{p-value\ =\ 0.001596}, and the degrees of freedom all agreed (\texttt{df\ =\ 98}) with what we have estimated manually. Importantly, this t-test assumes relative similarity of variance between groups.

\hypertarget{t-test-with-unequal-variance}{%
\subsection{t-test with unequal variance}\label{t-test-with-unequal-variance}}

The relative similarity of variance between groups could be an unrealistic assumption. Luckily, there is a variant of t-test ``Welch's t-test,'' in which we assume unequal variance between groups. The implementation is easy -- set \texttt{var.equal\ =\ FALSE} in \texttt{t.test()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(x, y, }\AttributeTok{var.equal =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Welch Two Sample t-test
## 
## data:  x and y
## t = -3.2473, df = 95.846, p-value = 0.001606
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -3.3127929 -0.7992071
## sample estimates:
## mean of x mean of y 
##    13.350    15.406
\end{verbatim}

In Welch's t-test, t-statistics are defined differently to account for unequal variance between groups\footnote{When \(\hat{\sigma}^2_a \approx \hat{\sigma}_b^2\), the t-statistic for Welch's t-test is reduced to the original t-statistic.}:

\[
t = \frac{\hat{\mu_a} - \hat{\mu_b}}{\sqrt{\left(\frac{\hat{\sigma}^2_a}{N_a} + \frac{\hat{\sigma}^2_b}{N_b}\right)}}
\]

This t-statistic is known to follow the Student's t-distribution with the degrees of freedom:

\[
d.f. = \frac{\frac{\hat{\sigma}^2_a}{N_a} + \frac{\hat{\sigma}^2_b}{N_b}}{\frac{(\hat{\sigma}^2_a / N_a)^2}{N_a - 1} + \frac{(\hat{\sigma}^2_b/N_b)^2}{N_b-1}}
\]

Therefore, the reported values of t-statistic and d.f. are different from what we estimated. The Welch's t-test covers the cases for equal variances; therefore, by default, we use the Welch's test.

\hypertarget{laboratory-3}{%
\section{Laboratory}\label{laboratory-3}}

\hypertarget{multiple-group-comparison}{%
\chapter{Multiple-Group Comparison}\label{multiple-group-comparison}}

The t-test is used to compare two groups, but when there are more than two groups, ANOVA (Analysis of Variance) is employed. ANOVA allows for simultaneous comparison of means among multiple groups to determine if there are statistically significant differences. ANOVA uses the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Partition the total variability into \textbf{between-group} and \textbf{within-group} components.
\item
  Define a \textbf{test statistic} as a ratio of between-group variability to within-group variability (F statistic).
\item
  Define a probability distribution of F-statistic under the null hypothesis.
\item
  Estimate the probability of yielding greater the observed test statistic.
\end{enumerate}

If appropriate, post-hoc tests can be conducted to identify specific differing groups.

\hypertarget{partition-the-variability}{%
\section{Partition the Variability}\label{partition-the-variability}}

The first step is to determine what aspect to examine. In the case of a t-test, we focus on the difference in sample means between groups. One might initially consider conducting t-tests for all possible combinations. However, this approach leads to a problem known as the \href{https://en.wikipedia.org/wiki/Multiple_comparisons_problem\#:~:text=In\%20statistics\%2C\%20the\%20multiple\%20comparisons,based\%20on\%20the\%20observed\%20values.}{multiple comparisons problem}. Hence, this is not a viable option. Therefore, we need to explore the data from a different perspective.

To facilitate learning, let's once again utilize the lake fish data, but this time we have three lakes in our analysis:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_anova }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data\_raw/data\_fish\_length\_anova.csv"}\NormalTok{)}
\FunctionTok{distinct}\NormalTok{(df\_anova, lake)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 1
##   lake 
##   <chr>
## 1 a    
## 2 b    
## 3 c
\end{verbatim}

Visualization can be helpful in understanding how the data is distributed. While mean \(\pm\) SD is perfectly fine here, let me use a violin plot to show a different way of visualization.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# geom\_violin() {-} function for violin plots}
\CommentTok{\# geom\_jitter() {-} jittered points}

\NormalTok{df\_anova }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ lake,}
             \AttributeTok{y =}\NormalTok{ length)) }\SpecialCharTok{+}
  \FunctionTok{geom\_violin}\NormalTok{(}\AttributeTok{draw\_quantiles =} \FloatTok{0.5}\NormalTok{, }\CommentTok{\# draw median horizontal line}
              \AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# transparency}
  \FunctionTok{geom\_jitter}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\CommentTok{\# transparency}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{_main_files/figure-latex/violin-1} 

}

\caption{Violin plot for fish length in three lakes.}\label{fig:violin}
\end{figure}

It appears that Lake \texttt{b} exhibits a larger average body size compared to the other lakes. One approach to quantifying this difference between groups is by examining the ratio of between-group variability to within-group variability. \textbf{If we observe a greater between-group variability relative to within-group variability, it suggests that the differences among the groups are substantial.} In other words, much of the observed variation is explained by the group structure (lake).

Let me denote between-group and within-group variability as \(S_w\) and \(S_a\), respectively, which are defined as follows:

\[
\begin{aligned}
S_a &= \sum_g \sum_i (\hat{\mu}_{g(i)} - \hat{\mu})^2\\
S_w &= \sum_g \sum_i (x_{i} - \hat{\mu}_{g(i)})^2
\end{aligned}
\]

The double summation \(\sum_g \sum_i\) might scare you, but no worries. We can decompose this equation into two steps.

\hypertarget{between-group-variability}{%
\subsection{Between-group variability}\label{between-group-variability}}

Let me first consider \(S_a = \sum_g \sum_i (\hat{\mu}_{g(i)} - \hat{\mu})^2\). In this equation, \(\hat{\mu}\) is the overall mean of the fish length and \(\hat{\mu}_{g(i)}\) is the group-mean in a given lake (\(g = \{a, b, c\}\)). Let's perform this estimation in R:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# estimate overall mean}
\NormalTok{mu }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(df\_anova}\SpecialCharTok{$}\NormalTok{length)}

\CommentTok{\# estimate group means and sample size each}
\NormalTok{df\_g }\OtherTok{\textless{}{-}}\NormalTok{ df\_anova }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(lake) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mu\_g =} \FunctionTok{mean}\NormalTok{(length), }\CommentTok{\# mean for each group}
            \AttributeTok{dev\_g =}\NormalTok{ (mu\_g }\SpecialCharTok{{-}}\NormalTok{ mu)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\CommentTok{\# squared deviation for each group}
            \AttributeTok{n =} \FunctionTok{n}\NormalTok{()) }\CommentTok{\# sample size for each group}

\FunctionTok{print}\NormalTok{(df\_g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##   lake   mu_g   dev_g     n
##   <chr> <dbl>   <dbl> <int>
## 1 a      13.4 1.12       50
## 2 b      15.4 0.997      50
## 3 c      14.5 0.00344    50
\end{verbatim}

In the column \texttt{dev\_g}, we estimated \((\hat{\mu}_{g(i)} - \hat{\mu})^2\). We must sum over \(i\) (fish individual) to get the variability in each lake (\(\sum_i (\hat{\mu}_{g(i)} - \hat{\mu})^2\)). Since \(\hat{\mu}_{g(i)}\) is constant in each lake, we can simply multiply \texttt{dev\_g} with sample size \texttt{n} in each lake:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_g }\OtherTok{\textless{}{-}}\NormalTok{ df\_g }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ss =}\NormalTok{ dev\_g }\SpecialCharTok{*}\NormalTok{ n)}

\FunctionTok{print}\NormalTok{(df\_g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   lake   mu_g   dev_g     n     ss
##   <chr> <dbl>   <dbl> <int>  <dbl>
## 1 a      13.4 1.12       50 55.9  
## 2 b      15.4 0.997      50 49.9  
## 3 c      14.5 0.00344    50  0.172
\end{verbatim}

Sum over \(g\) (lake) to get \(S_a\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s\_a }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(df\_g}\SpecialCharTok{$}\NormalTok{ss)}
\FunctionTok{print}\NormalTok{(s\_a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 105.9365
\end{verbatim}

\hypertarget{within-group-variability}{%
\subsection{Within-group variability}\label{within-group-variability}}

We can follow the same steps to estimate the within-group variability \(S_w = \sum_g \sum_i (x_{i} - \hat{\mu}_{g(i)})^2\). Let's estimate \((x_{i} - \hat{\mu}_{g(i)})^2\) first:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_i }\OtherTok{\textless{}{-}}\NormalTok{ df\_anova }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(lake) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{mu\_g =} \FunctionTok{mean}\NormalTok{(length)) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# use mutate() to retain individual rows}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{dev\_i =}\NormalTok{ (length }\SpecialCharTok{{-}}\NormalTok{ mu\_g)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\CommentTok{\# deviation from group mean for each fish}
\end{Highlighting}
\end{Shaded}

You can take a look at group-level data with the following code; the column \texttt{mu\_g} contains group-specific means of fish length, and \texttt{dev\_i} contains \((x_{g(i)} - \hat{\mu}_{g(i)})^2\):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# filter() \& slice(): show first 3 rows each group}
\FunctionTok{print}\NormalTok{(df\_i }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(lake }\SpecialCharTok{==} \StringTok{"a"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{))}

\FunctionTok{print}\NormalTok{(df\_i }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(lake }\SpecialCharTok{==} \StringTok{"b"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{))}

\FunctionTok{print}\NormalTok{(df\_i }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(lake }\SpecialCharTok{==} \StringTok{"c"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Sum over \(i\) in each lake \(g\) (\(\sum_i (x_{g(i)} - \hat{\mu}_{g(i)})^2\)):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_i\_g }\OtherTok{\textless{}{-}}\NormalTok{ df\_i }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(lake) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{ss =} \FunctionTok{sum}\NormalTok{(dev\_i))}

\FunctionTok{print}\NormalTok{(df\_i\_g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   lake     ss
##   <chr> <dbl>
## 1 a      417.
## 2 b      565.
## 3 c      486.
\end{verbatim}

Then sum over \(g\) to get \(S_w\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s\_w }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(df\_i\_g}\SpecialCharTok{$}\NormalTok{ss)}
\FunctionTok{print}\NormalTok{(s\_w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1467.645
\end{verbatim}

\hypertarget{variability-to-variance}{%
\subsection{Variability to Variance}\label{variability-to-variance}}

I referred to \(S_a\) and \(S_w\) as ``variability,'' which essentially represents the summation of squared deviations. To convert them into variances, we can divide them by appropriate numbers. In Chapter \ref{sampling}, I mentioned that the denominator for variance is the sample size minus one. The same principle applies here, but with caution.

For the between-group variability, denoted as \(S_a\), the realized sample size is the number of groups, \(N_g\), which in this case is three (representing the number of lakes). Therefore, we divide by three minus one to obtain an unbiased estimate of the between-group variance, denoted as \(\hat{\sigma}_a^2"\):

\[
\hat{\sigma}^2_a = \frac{S_a}{N_g-1}
\]

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# n\_distinct() count the number of unique elements}
\NormalTok{n\_g }\OtherTok{\textless{}{-}} \FunctionTok{n\_distinct}\NormalTok{(df\_anova}\SpecialCharTok{$}\NormalTok{lake)}
\NormalTok{s2\_a }\OtherTok{\textless{}{-}}\NormalTok{ s\_a }\SpecialCharTok{/}\NormalTok{ (n\_g }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\FunctionTok{print}\NormalTok{(s2\_a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 52.96827
\end{verbatim}

Meanwhile, we need to be careful when estimating the within-group variance. Since the within-group variance is measured at the individual level, the number of data used is equal to the number of fish individuals. Yet, we subtract the number of groups -- while the rationale behind this is beyond the scope, we are essentially accounting for the fact that some of the degrees of freedom are ``used up'' in estimating the group means. As such, we estimate the within-group variance \(\hat{\sigma}^2_w\) as follows:

\[
\hat{\sigma}^2_w = \frac{S_w}{N-N_g}
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s2\_w }\OtherTok{\textless{}{-}}\NormalTok{ s\_w }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{nrow}\NormalTok{(df\_anova) }\SpecialCharTok{{-}}\NormalTok{ n\_g)}
\FunctionTok{print}\NormalTok{(s2\_w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 9.983982
\end{verbatim}

\hypertarget{test-statistic-1}{%
\section{Test Statistic}\label{test-statistic-1}}

\hypertarget{f-statistic}{%
\subsection{F-statistic}\label{f-statistic}}

In ANOVA, we use F-statistic -- the ratio of between-group variability to within-group variability. The above exercise was essentially performed to yield this test statistic:

\[
F = \frac{\text{between-group variance}}{\text{within-group variance}} = \frac{\hat{\sigma}^2_a}{\hat{\sigma}^2_w}
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f\_value }\OtherTok{\textless{}{-}}\NormalTok{ s2\_a }\SpecialCharTok{/}\NormalTok{ s2\_w}
\FunctionTok{print}\NormalTok{(f\_value)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5.305325
\end{verbatim}

The F-statistic in our data was calculated to be 5.31. This indicates that the between-group variance is approximately five times higher than the within-group variance. While this difference appears significant, it is important to determine whether it is statistically substantial. To make such a claim, we can use the Null Hypothesis as a reference.

\hypertarget{null-hypothesis-1}{%
\subsection{Null Hypothesis}\label{null-hypothesis-1}}

The F-statistic follows an F-distribution when there is no difference in means among the groups. Therefore, the null hypothesis we are considering in our example is that the means of all groups are equal, represented as \(\mu_a = \mu_b = \mu_c\). It's worth noting that the alternative hypotheses can take different forms, such as \(\mu_a \ne \mu_b = \mu_c\), \(\mu_a = \mu_b \ne \mu_c\), or \$\mu\_a \ne \mu\_b \ne \mu\_c`. ANOVA, however, is unable to distinguish between these alternative hypotheses.

The degrees of freedom in an F-distribution are determined by two parameters: \(N_g - 1\) and \$N - N\_g\texttt{.\ To\ visualize\ the\ distribution,\ you\ can\ utilize\ the}df()` function. Similar to the t-test, we can plot the F-distribution and draw a vertical line to represent the observed F-statistic. This approach allows us to assess the position of the observed F-statistic within the distribution and determine the associated p-value.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{df}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{df1 =}\NormalTok{ n\_g }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\AttributeTok{df2 =} \FunctionTok{nrow}\NormalTok{(df\_anova) }\SpecialCharTok{{-}}\NormalTok{ n\_g)}

\FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x,}
             \AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+} \CommentTok{\# F distribution}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ f\_value,}
             \AttributeTok{color =} \StringTok{"salmon"}\NormalTok{) }\CommentTok{\# observed F{-}statistic}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{_main_files/figure-latex/f-dist-1} 

}

\caption{F-distribution. The vertical red line denotes the observed F-statistic.}\label{fig:f-dist}
\end{figure}

Unlike t-statistics, F-statistics can take only positive values (because F-statistics are the ratio of positive values). The p-value here is \(\Pr(F >F_0)\), where \(F_0\) is the possible F-statistics under the null hypothesis. Let's estimate this probability using \texttt{pf()}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# pf() estimate the probability of less than q}
\CommentTok{\# Pr(F \textgreater{} F0) is 1 {-} Pr(F \textless{} F0)}
\NormalTok{p\_value }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pf}\NormalTok{(}\AttributeTok{q =}\NormalTok{ f\_value, }\AttributeTok{df1 =}\NormalTok{ n\_g }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, }\AttributeTok{df2 =} \FunctionTok{nrow}\NormalTok{(df\_anova) }\SpecialCharTok{{-}}\NormalTok{ n\_g)}
\FunctionTok{print}\NormalTok{(p\_value)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.00596054
\end{verbatim}

\hypertarget{anova-in-r}{%
\section{ANOVA in R}\label{anova-in-r}}

Like the t-test, R provides functions to perform ANOVA easily. In this case, we will utilize the \texttt{aov()} function. The first argument of this function is the ``formula,'' which is used to describe the structure of the model. In our scenario, we aim to explain the fish body length by grouping them according to lakes. In the formula expression, we represent this relationship as \texttt{length\ \textasciitilde{}\ lake}, using the tilde symbol (\textasciitilde) to indicate the stochastic nature of the relationship.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# first argument is formula}
\CommentTok{\# second argument is data frame for reference}
\CommentTok{\# do not forget specify data = XXX! aov() refer to columns in the data frame}
\NormalTok{m }\OtherTok{\textless{}{-}} \FunctionTok{aov}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ length }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lake,}
         \AttributeTok{data =}\NormalTok{ df\_anova)}

\FunctionTok{print}\NormalTok{(m)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
##    aov(formula = length ~ lake, data = df_anova)
## 
## Terms:
##                      lake Residuals
## Sum of Squares   105.9365 1467.6454
## Deg. of Freedom         2       147
## 
## Residual standard error: 3.159744
## Estimated effects may be unbalanced
\end{verbatim}

The function returns \texttt{Sum\ of\ Squares} and \texttt{Deg.\ of\ Freedom} -- these value matches what we have calculated. To get deeper insights, wrap the object with \texttt{summary()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(m)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              Df Sum Sq Mean Sq F value  Pr(>F)   
## lake          2  105.9   52.97   5.305 0.00596 **
## Residuals   147 1467.6    9.98                   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

The F-statistic and p-value are identical to our manual estimate.

\hypertarget{post-hoc-tests}{%
\section{Post-hoc Tests}\label{post-hoc-tests}}

When conducting an ANOVA and finding a significant difference among group means, a post-hoc test is often performed to determine which specific groups differ significantly from each other. Post-hoc tests help to identify pairwise comparisons that contribute to the observed overall difference.

There are several post-hoc tests available for ANOVA, including:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Tukey's Honestly Significant Difference (HSD): This test compares all possible pairs of group means and provides adjusted p-values to control for the family-wise error rate. It is a commonly used and reliable post-hoc test.
\item
  Bonferroni correction: This method adjusts the significance level for each individual comparison to control the overall Type I error rate. The adjusted p-value is obtained by dividing the desired significance level (e.g., 0.05) by the number of comparisons.
\item
  Scheffe's test: This test controls the family-wise error rate by considering all possible pairwise comparisons. It is more conservative than Tukey's HSD, but it is suitable for cases where specific comparisons are of particular interest.
\item
  Dunnett's test: This test is useful when comparing multiple groups against a control group. It controls the overall error rate by conducting multiple t-tests between the control group and each of the other groups.
\end{enumerate}

The choice of post-hoc test depends on the specific research question, assumptions, and desired control of the Type I error rate. It is important to select an appropriate test and interpret the results accordingly to draw valid conclusions about group differences in an ANOVA analysis.

\hypertarget{laboratory-4}{%
\section{Laboratory}\label{laboratory-4}}

\hypertarget{appendix-project-management}{%
\chapter{Appendix: Project Management}\label{appendix-project-management}}

\hypertarget{r-project}{%
\section{R Project}\label{r-project}}

For the entirety of this book, I will utilize the `R Project' as the fundamental unit of workspace, where all relevant materials such as R scripts (\texttt{.R}) and data files are gathered together. There are multiple ways to organize your project, but my preferred approach is to create a single `R Project' for a collection of scripts and data that will contribute to a single publication (see example \href{https://github.com/aterui/public-proj_stream-diversity}{here}). To set up an `R Project,' you will need to have both \emph{RStudio} and the base \emph{R} software installed. Although \emph{R} can be used as a standalone software, I highly recommend using it in conjunction with \emph{RStudio} due to the latter's many features that facilitate data analysis. You can download \emph{R} and \emph{RStudio} from the following websites:

\begin{itemize}
\tightlist
\item
  \href{https://www.r-project.org/}{R} (you can select any CRAN mirror for downloading)
\item
  RStudio
\end{itemize}

Once you launch \emph{RStudio}, you will be greeted by the interface shown in Figure \ref{fig:ui}. The interface consists of three primary panels upon first opening it: the \texttt{Console}, \texttt{Environment}, and \texttt{Files}. The \texttt{Console} is where you write your code and execute calculations, data manipulation, and analysis. The \texttt{Environment} panel lists the objects you have saved, and the \texttt{Files} panel displays any files in a designated location on your computer.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"image/r\_image01.png"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=9.47in]{image/r_image01} 

}

\caption{RStudio interface.}\label{fig:ui}
\end{figure}

After pasting the script into the console, you should see the variable \texttt{x} appear in the environment panel.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\texttt{x} is an \textbf{object} where information is stored. In this case, we have stored a sequence of \texttt{1} and \texttt{2} in the object \texttt{x}. Once you have stored information in \texttt{x}, you can access it by simply typing \texttt{x}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2
\end{verbatim}

Great! You can indeed work on your data in this manner, but it is important to note that \textbf{it is generally considered a poor practice}. As you progress through your project, you will generate a significant amount of materials, such as writing over 2000 lines of code for a single project. Therefore, it becomes crucial to implement effective code management strategies. How do you currently manage your code?

\hypertarget{script-editor}{%
\subsection{Script Editor}\label{script-editor}}

It is highly recommended to manage your scripts in the \texttt{Editor} instead. The \texttt{Editor} is where you draft and fine-tune your code before executing it in the \texttt{Console}. To create space for the \texttt{Editor}, press \texttt{Ctrl\ +\ Shift\ +\ N}. A new panel will appear in the top left corner. Let's type the following script in the \texttt{Editor}. Please note that the key combination \texttt{Ctrl\ +\ Shift\ +\ N} assumes a Windows or Linux operating system. If you're using a Mac, you can use \texttt{Command\ +\ Shift\ +\ N} instead.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Then, hit \texttt{Ctr\ +\ S} to save the \texttt{Editor} file. \emph{RStudio} will prompt you to enter the file name of the \texttt{Editor}\footnote{In \emph{R}, an editor file has an extension of \texttt{.R}.}.

\hypertarget{file-name}{%
\subsection{File Name}\label{file-name}}

It is also crucial to establish consistent naming \textbf{rules} for your files. As your project progresses, the number of files within each sub-directory may increase significantly. Without clear and consistent naming rules for your files, navigating through the project can become challenging, not only for yourself but also for others involved. To alleviate this issue, consider implementing the following recommendations for file naming:

\begin{itemize}
\tightlist
\item
  \textbf{NO SPACE.} Use underscore.

  \begin{itemize}
  \tightlist
  \item
    Do: \texttt{script\_week1.R}
  \item
    Don't: \texttt{script\ week1.R}
  \end{itemize}
\item
  \textbf{NO UPPERCASE.} Use lowercase for file names.

  \begin{itemize}
  \tightlist
  \item
    Do: \texttt{script\_week1.R}
  \item
    Don't: \texttt{Script\_week1.R}
  \end{itemize}
\item
  \textbf{BE CONSISTENT.} Apply consistent naming rules within a project.

  \begin{itemize}
  \tightlist
  \item
    Do: R scripts for figures always start with a common prefix, e.g., \texttt{figure\_XXX.R} \texttt{figure\_YYY.R}(\texttt{XXX} and \texttt{YYY} specifies further details).
  \item
    Don't: R scripts for figures start with random text, e.g., \texttt{XXX\_fig.R} , \texttt{Figure\_Y2.R} , \texttt{plotB.R}.
  \end{itemize}
\end{itemize}

\hypertarget{structure-your-project}{%
\subsection{Structure Your Project}\label{structure-your-project}}

If you fail to save or haphazardly store your code files on your computer, the risk of losing essential items becomes inevitable sooner or later. To mitigate this risk, I highly recommend gathering all the relevant materials within a single \texttt{R\ Project}. To create a new \texttt{R\ Project}, follow the procedure outlined below:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Go to \texttt{File\ \textgreater{}\ New\ Project} on the top menu
\item
  Select \texttt{New\ Directory}
\item
  Select \texttt{New\ Project}
\end{enumerate}

A new window will appear, prompting you to name a directory and select a location on your computer. To choose a location for the directory, click on the `Browse' button. When organizing your project directories on your computer, I highly recommend creating a dedicated space. For instance, on my computer, I have a folder named \texttt{/github} where I store all my \texttt{R\ Project} directories.

The internal structure of an \texttt{R\ Project} is crucial for effective navigation and ensures clarity for both yourself and others when it is published. An \texttt{R\ Project} typically consists of various file types, such as \texttt{.R}, \texttt{.csv}, \texttt{.rds}, \texttt{.Rmd}, and others. Without an organized arrangement of these files, there is a high probability of encountering significant coding errors. Therefore, I place great importance on maintaining a well-structured project. In Table \ref{tab:str}, I present my recommended subdirectory structure.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.0691}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.9309}}@{}}
\caption{\label{tab:str} Suggested internal structure of \texttt{R\ Project}}\tabularnewline
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Name
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Content
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Name
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Content
\end{minipage} \\
\midrule()
\endhead
\texttt{README.md} & Markdown file explaining contents in the \texttt{R\ Project}. Can be derived from \texttt{README.Rmd}. \\
\texttt{/code} & Sub-directory for R scripts (\texttt{.R}). \\
\texttt{/data\_raw} & Sub-directory for raw data before data manipulation (\texttt{.csv} or other formats). Files in this sub-directory MUST NOT be modified unless there are changes to raw data entries. \\
\texttt{/data\_fmt} & Sub-directory for formatted data (\texttt{.csv}, \texttt{.rds}, or other formats). \\
\texttt{/output} & Sub-directory for result outputs (\texttt{.csv}, \texttt{.rds}, or other formats). This may include statistical estimates from linear regression models etc. \\
\texttt{/rmd} & (Optional) Sub-directory for Rmarkdown files (\texttt{.Rmd}). Rmarkdown allows seamless integration of R scripts and text. \\
\bottomrule()
\end{longtable}

\hypertarget{robust-coding}{%
\section{Robust coding}\label{robust-coding}}

While it is not mandatory, I highly recommend using \emph{RStudio} in conjunction with \emph{Git} and \emph{GitHub}. Coding is inherently prone to errors, and even the most skilled programmers make mistakes---without exception. However, the crucial difference between beginner and advanced programmers lies in their ability to develop robust coding practices accompanied by a self-error-detection system. \emph{Git} plays a vital role in this process. Throughout this book, I will occasionally delve into the importance of \emph{Git} and its usage.

\end{document}
