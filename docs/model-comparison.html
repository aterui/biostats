<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 16 Model Comparison | BIOSTATS</title>
<meta name="author" content="Akira Terui">
<meta name="description" content="We have acquired knowledge on constructing models and evaluating their performance. However, the challenge lies in selecting the “optimal” model from a pool of potential candidates. Some may think...">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="Chapter 16 Model Comparison | BIOSTATS">
<meta property="og:type" content="book">
<meta property="og:description" content="We have acquired knowledge on constructing models and evaluating their performance. However, the challenge lies in selecting the “optimal” model from a pool of potential candidates. Some may think...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 16 Model Comparison | BIOSTATS">
<meta name="twitter:description" content="We have acquired knowledge on constructing models and evaluating their performance. However, the challenge lies in selecting the “optimal” model from a pool of potential candidates. Some may think...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.8.0/transition.js"></script><script src="libs/bs3compat-0.8.0/tabs.js"></script><script src="libs/bs3compat-0.8.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><!-- Google tag (gtag.js) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-QZSNHVQQNV"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-QZSNHVQQNV');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">BIOSTATS</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Introduction</a></li>
<li class="book-part">Getting Started</li>
<li><a class="" href="what-is-r-and-r-studio.html"><span class="header-section-number">1</span> What is R and R studio?</a></li>
<li><a class="" href="installing-r-and-rstudio.html"><span class="header-section-number">2</span> Installing R and RStudio</a></li>
<li><a class="" href="r-project.html"><span class="header-section-number">3</span> R Project</a></li>
<li class="book-part">R Basics</li>
<li><a class="" href="data-structure.html"><span class="header-section-number">4</span> Data Structure</a></li>
<li><a class="" href="data-manipulation.html"><span class="header-section-number">5</span> Data Manipulation</a></li>
<li><a class="" href="visualization.html"><span class="header-section-number">6</span> Visualization</a></li>
<li class="book-part">Basic Statistics</li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">7</span> Descriptive Statistics</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">8</span> Sampling</a></li>
<li><a class="" href="probabilistic-view.html"><span class="header-section-number">9</span> Probabilistic View</a></li>
<li><a class="" href="two-group-comparison.html"><span class="header-section-number">10</span> Two-Group Comparison</a></li>
<li><a class="" href="multiple-group-comparison.html"><span class="header-section-number">11</span> Multiple-Group Comparison</a></li>
<li><a class="" href="regression.html"><span class="header-section-number">12</span> Regression</a></li>
<li><a class="" href="linear-model.html"><span class="header-section-number">13</span> Linear Model</a></li>
<li><a class="" href="generalized-linear-model.html"><span class="header-section-number">14</span> Generalized Linear Model</a></li>
<li><a class="" href="likelihood.html"><span class="header-section-number">15</span> Likelihood</a></li>
<li><a class="active" href="model-comparison.html"><span class="header-section-number">16</span> Model Comparison</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="git-github.html">Git &amp; GitHub</a></li>
<li><a class="" href="base-plot.html">Base Plot</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/aterui/biostats">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="model-comparison" class="section level1" number="16">
<h1>
<span class="header-section-number">16</span> Model Comparison<a class="anchor" aria-label="anchor" href="#model-comparison"><i class="fas fa-link"></i></a>
</h1>
<p>We have acquired knowledge on constructing models and evaluating their performance. However, the challenge lies in selecting the “optimal” model from a pool of potential candidates. Some may think that we can employ metrics like the Coefficient of Determination (<span class="math inline">\(\mbox{R}^2\)</span>) to compare and choose superior models; however, a predicament arises because these metrics tend to favor models with a larger number of explanatory variables, even if some of those variables are actually irrelevant and do not contribute meaningfully to the model’s effectiveness. In this Chapter, I introduce some popular methods to balance the trade-off between a goodness of fit and model’s complexity.</p>
<p><strong>Key words:</strong> adjusted <span class="math inline">\(\mbox{R}^2\)</span>, likelihood ratio test, Akaike’s Information Criterion</p>
<div id="model-fit-and-complexity" class="section level2" number="16.1">
<h2>
<span class="header-section-number">16.1</span> Model Fit and Complexity<a class="anchor" aria-label="anchor" href="#model-fit-and-complexity"><i class="fas fa-link"></i></a>
</h2>
<p>In the field of biological sciences, it is common to encounter multiple hypotheses or the need for exploratory analysis. In such instances, it becomes necessary to develop various models, each corresponding to a specific hypothesis, and subsequently compare their respective performances. The crucial aspect lies in how we quantify the “performance” of these models, acknowledging that this term can be somewhat ambiguous. As the determination of model performance ultimately dictates which model is superior, it profoundly impacts the conclusions drawn from the research. Thus, the significance of this process cannot be overstated.</p>
<p>One potential approach is to utilize the Coefficient of Determination (Chapter <a href="regression.html#regression">12</a>) as a measure of model performance. These metrics provide an indication of the proportion of variation in the response variable that is explained by the model, making them reasonable options. However, there are situations where these measures are not meaningful for <strong>model comparison</strong>.</p>
<p>To illustrate this, let’s consider the following simulated data. The advantage of using simulated data is that we already know the correct outcomes, enabling us to validate and verify the analysis results.</p>
<div class="sourceCode" id="cb462"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> <span class="co"># for reproducibility</span></span>
<span></span>
<span><span class="co"># hypothetical sample size</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span></span>
<span><span class="co"># true intercept and slope</span></span>
<span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># hypothetical explanatory variable</span></span>
<span><span class="va">x1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># create a design matrix</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="op">~</span><span class="va">x1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># expected values of y is a function of x</span></span>
<span><span class="co"># %*% means matrix multiplication</span></span>
<span><span class="co"># y = X %*% b equals y = b[1] + b[2] * x</span></span>
<span><span class="co"># recall linear algebra</span></span>
<span><span class="va">y_hat</span> <span class="op">&lt;-</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">b</span></span>
<span></span>
<span><span class="co"># add normal errors</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="va">y_hat</span>, sd <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot</span></span>
<span><span class="va">df0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tibble/man/tibble.html">tibble</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, x1 <span class="op">=</span> <span class="va">x1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">df0</span> <span class="op"><a href="https://rdrr.io/pkg/magrittr/man/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/ggplot2/man/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/ggplot2/man/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>,</span>
<span>             x <span class="op">=</span> <span class="va">x1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/ggplot2/man/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sim-data"></span>
<img src="biostats_files/figure-html/sim-data-1.png" alt="Simulated data" width="672"><p class="caption">
Figure 16.1: Simulated data
</p>
</div>
<p>The above code generated the response variable, denoted as <span class="math inline">\(y\)</span>, as a function of the variable <span class="math inline">\(x_1\)</span> (<span class="math inline">\(y_i = \beta_0 + \beta_1 x_1 + \varepsilon_i\)</span>). The values of the intercept and slope were set to 0.1 and 0.5 respectively. Given our knowledge of how this data was generated, we can establish the “correct” model. Now, let’s assess the performance of this model:</p>
<div class="sourceCode" id="cb463"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># correct model used to generate the data</span></span>
<span><span class="va">m1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span>, data <span class="op">=</span> <span class="va">df0</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1, data = df0)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.93842 -0.30688 -0.06975  0.26970  1.17309 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.08115    0.04849   1.673   0.0974 .  
## x1           0.49947    0.05386   9.273 4.58e-15 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4814 on 98 degrees of freedom
## Multiple R-squared:  0.4674, Adjusted R-squared:  0.4619 
## F-statistic: 85.99 on 1 and 98 DF,  p-value: 4.583e-15</code></pre>
<p>The estimated values for the intercept and slope of the model are approximately 0.08 and 0.5 respectively, which are reasonably close to the true values. The coefficient of determination, indicating the proportion of variation in the response variable explained by the model, is 0.467.</p>
<p>Now, let’s consider the scenario where we include another variable, <code>x2</code>, that is completely irrelevant.</p>
<div class="sourceCode" id="cb465"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># add a column x2 which is irrelevant for y</span></span>
<span><span class="va">df0</span> <span class="op">&lt;-</span> <span class="va">df0</span> <span class="op"><a href="https://rdrr.io/pkg/magrittr/man/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/dplyr/man/mutate.html">mutate</a></span><span class="op">(</span>x2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># add x2 to the model</span></span>
<span><span class="va">m2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span> <span class="op">+</span> <span class="va">x2</span>, data <span class="op">=</span> <span class="va">df0</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2, data = df0)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.92274 -0.32325 -0.07538  0.26640  1.16629 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.08178    0.04870   1.679   0.0963 .  
## x1           0.49996    0.05408   9.244 5.75e-15 ***
## x2          -0.02294    0.04697  -0.488   0.6264    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4833 on 97 degrees of freedom
## Multiple R-squared:  0.4687, Adjusted R-squared:  0.4577 
## F-statistic: 42.78 on 2 and 97 DF,  p-value: 4.793e-14</code></pre>
<p>Surprisingly, the <span class="math inline">\(\mbox{R}^2\)</span> value has increased to 0.469 even though the model includes the unnecessary variable.</p>
<p>This outcome occurs because the <span class="math inline">\(\mbox{R}^2\)</span> value does not consider the complexity of the model or the number of parameters employed. In fact, if we can increase the number of parameters indefinitely, it’s easy to construct a model with an <span class="math inline">\(\mbox{R}^2\)</span> value of <span class="math inline">\(1.00\)</span>. This is achieved by assigning <span class="math inline">\(N\)</span> parameters to <span class="math inline">\(N\)</span> data points, effectively making the parameters equivalent to the response variable itself. However, this approach is undesirable since the model essentially explains the response variable with the response variable (<span class="math inline">\(y = y\)</span>), which is self-evident. Therefore, if we aim to develop a meaningful model, it is essential to employ alternative measures for model comparisons.</p>
</div>
<div id="comparison-metrics" class="section level2" number="16.2">
<h2>
<span class="header-section-number">16.2</span> Comparison Metrics<a class="anchor" aria-label="anchor" href="#comparison-metrics"><i class="fas fa-link"></i></a>
</h2>
<p>While various measures exist to evaluate model performance, I will discuss three fundamental ones: Adjusted <span class="math inline">\(\mbox{R}^2\)</span>, the likelihood ratio test, and Akaike’s Information Criterion (AIC). The first two focus on <strong>how well the model fits the available dataset</strong> while appropriately considering model complexity. On the other hand, <strong>AIC assesses the model’s capability to make predictions on unseen data (“out-of-sample” prediction)</strong>. There is no universally optimal measure — it depends on the specific research objective. If the goal is to assess the model’s fit to the current data, any of the first two measures or other similar ones can be used. However, if evaluating the model’s predictive ability is the objective, AIC should be employed. The crucial factor to consider is that when comparing models, it is essential to ensure that:</p>
<ol style="list-style-type: decimal">
<li>The models use the same dataset. Models fitted to different data sets cannot be compared by no means.</li>
<li>They assume an identical probability distribution among candidate models. For example, a normal model cannot be compared with a Poisson model.</li>
</ol>
<p>I will now describe the rationale behind each method.</p>
<div id="adjusted-mboxr2" class="section level3" number="16.2.1">
<h3>
<span class="header-section-number">16.2.1</span> Adjusted <span class="math inline">\(\mbox{R}^2\)</span><a class="anchor" aria-label="anchor" href="#adjusted-mboxr2"><i class="fas fa-link"></i></a>
</h3>
<p>The Adjusted <span class="math inline">\(\mbox{R}^2\)</span> is a natural extension of the ordinary <span class="math inline">\(\mbox{R}^2\)</span>. The original formula for <span class="math inline">\(R^2\)</span> is:</p>
<p><span class="math display">\[
R^2 = 1 - \frac{SS}{SS_0}
\]</span></p>
<p>Here, <span class="math inline">\(SS\)</span> represents the sum of squares of residuals (<span class="math inline">\(\sum \varepsilon_i\)</span>), and <span class="math inline">\(SS_0\)</span> represents the sum of squares of the response variable (<span class="math inline">\(\sum (y_i - \mu_y)\)</span>, where <span class="math inline">\(\mu_y\)</span> is the sample mean of <span class="math inline">\(y\)</span>). The Adjusted <span class="math inline">\(R^2\)</span> modifies this formula to account for the number of parameters used:</p>
<p><span class="math display">\[
\begin{align*}
\text{Adj. }R^2 &amp;= 1 - \frac{SS/(N-k)}{SS_0/(N-1)} \\
&amp;= 1 - \frac{\sigma^2_{\varepsilon}}{\sigma^2_0}
\end{align*}
\]</span></p>
<p>In the equation above, <span class="math inline">\(k\)</span> denotes the number of parameters utilized in the model. Hence, the numerator indicates the residual variance of the model, <span class="math inline">\(\sigma^2_{\varepsilon}\)</span>, while the denominator represents the variance of the response variable, <span class="math inline">\(y\)</span>. We can obtain these values from the model objects <code>m1</code> and <code>m2</code>:</p>
<div class="sourceCode" id="cb467"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Adjusted R-square for m1 without x2</span></span>
<span><span class="va">sm1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">sm1</span><span class="op">$</span><span class="va">adj.r.squared</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.4619164</code></pre>
<div class="sourceCode" id="cb469"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Adjusted R-square for m2 with x2</span></span>
<span><span class="va">sm2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">sm2</span><span class="op">$</span><span class="va">adj.r.squared</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.4577026</code></pre>
<p>Now we can observe that the model <code>m2</code> exhibits a lower value of the adjusted <span class="math inline">\(\mbox{R}^2\)</span>. This discrepancy arises because the adjusted <span class="math inline">\(\mbox{R}^2\)</span> incorporates a penalty term for the inclusion of additional explanatory variables (<span class="math inline">\(k\)</span>). In order for the adjusted <span class="math inline">\(\mbox{R}^2\)</span> to decrease, the variable <code>x2</code> must significantly decrease <span class="math inline">\(\sigma^2_{\varepsilon}\)</span> beyond what would be expected by chance alone. In other words, <code>x2</code> needs to provide a substantial improvement in explaining the response variable to counterbalance the penalty imposed by the inclusion of an extra variable.</p>
<p>Note that both <span class="math inline">\(\mbox{R}^2\)</span> and <span class="math inline">\(\mbox{Adj. R}^2\)</span> are applicable only to normal models. In the case of the GLM framework (Chapter <a href="generalized-linear-model.html#generalized-linear-model">14</a>), we utilize a different measure called <span class="math inline">\(\mbox{R}^2_D\)</span>, where <span class="math inline">\(D\)</span> represents “deviance.” Deviance (<span class="math inline">\(D\)</span>) is defined as the negative twice the log-likelihood. We estimate <span class="math inline">\(\mbox{R}^2_D\)</span> using the deviance (<span class="math inline">\(D\)</span>), which is comparable to the traditional <span class="math inline">\(\mbox{R}^2\)</span> but tailored for GLMs.</p>
<p><span class="math display">\[
\begin{align}
\mbox{R}^2_D &amp;= 1 - \frac{-2 \ln L}{-2 \ln L_0}\\
&amp;= 1 - \frac{D}{D_0}
\end{align}
\]</span></p>
<p>In the above formula, <span class="math inline">\(L\)</span> (<span class="math inline">\(L_0\)</span>) represents the likelihood of the fitted (null) model, while <span class="math inline">\(D\)</span> (<span class="math inline">\(D_0\)</span>) represents the deviance. There are several substitutes available for <span class="math inline">\(\mbox{Adjusted R}^2\)</span>. One such method, known as McFadden’s method <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Note that this quantity can take a negative value&lt;/p&gt;"><sup>6</sup></a>, incorporates model complexity into the calculation using the following formula:</p>
<p><span class="math display">\[
\mbox{Adj. R}^2_{D} = 1 - \frac{\ln L - k}{\ln L_0}
\]</span></p>
</div>
<div id="likelihood-ratio-test" class="section level3" number="16.2.2">
<h3>
<span class="header-section-number">16.2.2</span> Likelihood Ratio Test<a class="anchor" aria-label="anchor" href="#likelihood-ratio-test"><i class="fas fa-link"></i></a>
</h3>
<p>Another possible approach is the likelihood ratio test, a statistical test used to compare the fit of two nested models. It calculates the log ratio of likelihoods of the two models to as a test statistic:</p>
<p><span class="math display">\[
\begin{align}
\mbox{LR} &amp;= -2 \ln \frac{L_0}{L_1}\\
&amp;= -2 (\ln L_0 - \ln L_1)
\end{align}
\]</span></p>
<p>The likelihoods of the null and alternative models are denoted as <span class="math inline">\(L_0\)</span> and <span class="math inline">\(L_1\)</span> respectively. Under the null hypothesis, the test statistic <span class="math inline">\(\mbox{LR}\)</span> follows a chi-square distribution, if the sample size approaches infinity. This enables us to determine whether the inclusion of a new variable (or variables) has significantly enhanced the model’s likelihood beyond what would be expected by chance.</p>
<p>We employ this approach because likelihood encounters a problem similar to <span class="math inline">\(\mbox{R}^2\)</span>. The log likelihood of the models can be obtained using the <code><a href="https://rdrr.io/r/stats/logLik.html">logLik()</a></code> function:</p>
<div class="sourceCode" id="cb471"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># log likelihood: correct model</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 'log Lik.' -67.77319 (df=3)</code></pre>
<div class="sourceCode" id="cb473"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># log likelihood: incorrect model</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">m2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 'log Lik.' -67.6504 (df=4)</code></pre>
<p>The model <code>m2</code> has a higher likelihood because likelihood is an absolute measure of model performance. However, the likelihood ratio test overcomes this limitation by comparing the observed increase in likelihood with what would be expected by chance. The test statistic <span class="math inline">\(\mbox{LR}\)</span> follows a chi-square distribution<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Rigorously speaking, if sample size approaches infinity. If the sample size is small, other methods (e.g., boot strap simulation) should be employed to calculate a p-value.&lt;/p&gt;"><sup>7</sup></a>, which serves as a reference distribution. The chi-square distribution has a single parameter - degrees of freedom - which, in this case, corresponds to the difference in the number of model parameters used.</p>
<p>The model <code>m1</code> utilized two parameters (intercept and one slope), whereas the model <code>m2</code> employed three parameters (intercept and two slopes). Consequently, the test statistic is assumed to follow a chi-square distribution with one degree of freedom. While it is possible to calculate the p-value manually, the <code><a href="https://rdrr.io/r/stats/anova.html">anova()</a></code> function can perform this analysis:</p>
<div class="sourceCode" id="cb475"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># test = "Chisq" specifies a chi-square distribution</span></span>
<span><span class="co"># as a distribution of LR</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">m1</span>, <span class="va">m2</span>, test <span class="op">=</span> <span class="st">"Chisq"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: y ~ x1
## Model 2: y ~ x1 + x2
##   Res.Df    RSS Df Sum of Sq Pr(&gt;Chi)
## 1     98 22.709                      
## 2     97 22.653  1  0.055702   0.6253</code></pre>
<p>The <code>Pr(&gt;Chi)</code> value, which represents the p-value, is significantly greater than 0.05. This indicates that the inclusion of variable <code>x2</code> does not improve the model’s likelihood than what would be expected by chance.</p>
<p>The likelihood ratio test can be applied to a wide range of models as long as they are capable of estimating likelihood. Therefore, this method is highly versatile. However, one limitation is that the competing models must be nested, meaning that the null model should be a subset of the alternative model. In the example provided, <code>m1</code> includes only the explanatory variable <code>x1</code>, while <code>m2</code> incorporates both <code>x1</code> and <code>x2</code>. However, <code>m1</code> can be viewed as a special case of <code>m2</code> where the slope of <code>x2</code> is fixed at zero. Thus, <code>m1</code> can be considered as a “nested” subset of <code>m2</code>.</p>
</div>
<div id="aic" class="section level3" number="16.2.3">
<h3>
<span class="header-section-number">16.2.3</span> AIC<a class="anchor" aria-label="anchor" href="#aic"><i class="fas fa-link"></i></a>
</h3>
<p>The AIC takes a different approach to evaluating model performance compared to other measures. While measures like <span class="math inline">\(\mbox{R}^2\)</span> primarily assess the goodness of fit to the available dataset used for model fitting, the AIC is rooted in the information theoretic perspective. It evaluates a model’s ability to predict unseen data from the same population.</p>
<p>The mathematical details of AIC are beyond the scope of this discussion, but for those interested, reference <a href="https://link.springer.com/book/10.1007/b97636">Burnham and Anderson 2002</a>. However, <strong>it is crucial to understand that the AIC differs fundamentally from other measures as it assesses the model’s robustness when new data is added.</strong></p>
<p>Despite the underlying mathematical complexity, the AIC formula is remarkably simple:</p>
<p><span class="math display">\[
\mbox{AIC} = 2k - 2\ln L
\]</span></p>
<p>Here, <span class="math inline">\(k\)</span> represents the number of model parameters, and <span class="math inline">\(L\)</span> is the likelihood. Lower AIC values indicate better predictability of the model. The formula consists of two terms: the first term is twice the number of parameters, and the second term is the model’s deviance. Thus, a lower AIC value is preferred. While one might perceive it as a variant of <span class="math inline">\(\mbox{R}^2\)</span> or similar measures, it is important to note that the penalty term in AIC was derived from the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback–Leibler divergence</a>.</p>
<p>As evident from the formula, AIC can be estimated for any model that has a valid likelihood, making this method widely applicable, including for GLMs. In R, the model’s AIC can be computed using the <code><a href="https://rdrr.io/r/stats/AIC.html">AIC()</a></code> function.</p>
<div class="sourceCode" id="cb477"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># AIC: correct model</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html">AIC</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 141.5464</code></pre>
<div class="sourceCode" id="cb479"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># AIC: incorrect model</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html">AIC</a></span><span class="op">(</span><span class="va">m2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 143.3008</code></pre>
<p>The AIC value for <code>m2</code> is higher, indicating that the second model has a lower capability to predict unseen data. AIC has several valuable features that make it a useful criterion. For instance, unlike likelihood tests, it can be used to compare more than two models. Moreover, in the field of biological sciences, where prediction often holds significant interest, AIC is particularly relevant. For example, it helps determine which model performs best when predicting unobserved sites within the same study region. AIC suggests that the selected “parsimonious” model with the lowest AIC would provide the best performance among the competing models. Consequently, AIC finds widespread use in biology, especially in ecology.</p>
<p>However, it is important to exercise caution when interpreting the results. Specifically:</p>
<ol style="list-style-type: decimal">
<li><p><strong>The model with the lowest AIC does not necessarily imply it is the “true” model.</strong> We are limited to the explanatory variables we have collected, and AIC can only indicate which model is better among the choices available. It is possible that all the candidate models are incorrect.</p></li>
<li><p><strong>AIC is not designed to infer causal mechanisms.</strong> Variables that are not causally related may enhance the model’s ability to predict unseen data. If the goal is causal inference, a different criterion, such as the backdoor criterion, should be employed. For example, AIC is not suitable for analyzing controlled experiments aimed at uncovering causal mechanisms in biology.</p></li>
</ol>
<p>There is often misuse of this metric, particularly in overlooking the second component (see arguments in <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/ele.14033">Arif and MacNeil 2022</a>). Therefore, it is crucial to clearly define the objective of your analysis to ensure the appropriate choice of statistical methods.</p>
</div>
</div>
<div id="laboratory-9" class="section level2" number="16.3">
<h2>
<span class="header-section-number">16.3</span> Laboratory<a class="anchor" aria-label="anchor" href="#laboratory-9"><i class="fas fa-link"></i></a>
</h2>
<div id="format-penguin-data" class="section level3" number="16.3.1">
<h3>
<span class="header-section-number">16.3.1</span> Format Penguin Data<a class="anchor" aria-label="anchor" href="#format-penguin-data"><i class="fas fa-link"></i></a>
</h3>
<p>The R package <code>palmerpenguins</code> provides penguin data that were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network. To get started, install this package onto your computer:</p>
<div class="sourceCode" id="cb481"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Perform only once</span></span>
<span><span class="co"># install.packages("palmerpenguins")</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://allisonhorst.github.io/palmerpenguins/">palmerpenguins</a></span><span class="op">)</span></span></code></pre></div>
<p>For this exercise, we will use the <code>penguins_raw</code> dataset. However, the dataset is not well-organized and may be prone to errors in its current format. Before delving into data analysis, let’s perform the following tasks:</p>
<ol style="list-style-type: decimal">
<li><p>Column names are a mix of upper and lower cases, and they contain white spaces. We need to format the column names as follows: (1) convert all characters to lowercase, (2) replace white spaces with underscores <code>_</code>, and (3) remove parentheses (e.g., <code>(mm)</code>). To accomplish this, we can use <code>clean_names()</code> function from <code>janitor</code> package. You can check their usage by typing <code>?function_name</code> in the R console.</p></li>
<li><p>In the following exercise, we will focus on the data in the <code>Clutch Completion</code> column, which records data as <code>Yes</code> or <code>No</code>. To make it more suitable for analysis, we need to convert this information to binary values: <code>1</code> for <code>Yes</code> and <code>0</code> for <code>No</code>. Use <code><a href="https://rdrr.io/r/base/ifelse.html">ifelse()</a></code> function in combination with <code><a href="https://rdrr.io/pkg/dplyr/man/mutate.html">mutate()</a></code>.</p></li>
<li><p>The <code>Species</code> column in the dataset contains species names such as Adelie Penguin (Pygoscelis adeliae), Chinstrap penguin (Pygoscelis antarctica), Gentoo penguin (Pygoscelis papua). We need to convert these species names to standardized ones, specifically: <code>adelie</code>, <code>chinstrap</code>, and <code>gentoo</code>. Use of the <code><a href="https://rdrr.io/pkg/dplyr/man/mutate.html">dplyr::mutate()</a></code> and <code><a href="https://rdrr.io/pkg/dplyr/man/case_when.html">dplyr::case_when()</a></code> functions for this task.</p></li>
<li><p>Lastly, we should remove any rows that contain missing values (<code>NA</code>) in the columns <code>Culmen Length (mm)</code>, <code>Culmen Depth (mm)</code>, <code>Flipper Length (mm)</code>, <code>Body Mass (g)</code>, and <code>Sex</code>. To achieve this, we can utilize the <code>dplyr::drop_na()</code> function.</p></li>
</ol>
</div>
<div id="analyze-penguin-data" class="section level3" number="16.3.2">
<h3>
<span class="header-section-number">16.3.2</span> Analyze Penguin Data<a class="anchor" aria-label="anchor" href="#analyze-penguin-data"><i class="fas fa-link"></i></a>
</h3>
<p>After formatting the data, our next step is to perform the following:</p>
<ol style="list-style-type: decimal">
<li><p>Develop a statistical model that explains <code>Clutch Completion</code> using the variables <code>Species</code>, <code>Culmen Length (mm)</code>, <code>Culmen Depth (mm)</code>, <code>Flipper Length (mm)</code>, <code>Body Mass (g)</code>, and <code>Sex</code>. Use an appropriate probability distribution for this model.</p></li>
<li><p>Perform an AIC-based model selection using the <code><a href="https://rdrr.io/pkg/MuMIn/man/dredge.html">MuMIn::dredge()</a></code> function. This process will help us identify the variables that are most important for predicting the clutch completion status.</p></li>
</ol>
<div class="sourceCode" id="cb482"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">MuMIn</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/options.html">options</a></span><span class="op">(</span>na.action <span class="op">=</span> <span class="st">"na.fail"</span><span class="op">)</span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="co">#model object</span></span>
<span><span class="va">m_set</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MuMIn/man/dredge.html">dredge</a></span><span class="op">(</span><span class="va">m</span>, rank <span class="op">=</span> <span class="st">"AIC"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">m_set</span>, <span class="va">delta</span> <span class="op">&lt;</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>

</div>
</div>
</div>




  <div class="chapter-nav">
<div class="prev"><a href="likelihood.html"><span class="header-section-number">15</span> Likelihood</a></div>
<div class="next"><a href="git-github.html">Git &amp; GitHub</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#model-comparison"><span class="header-section-number">16</span> Model Comparison</a></li>
<li><a class="nav-link" href="#model-fit-and-complexity"><span class="header-section-number">16.1</span> Model Fit and Complexity</a></li>
<li>
<a class="nav-link" href="#comparison-metrics"><span class="header-section-number">16.2</span> Comparison Metrics</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#adjusted-mboxr2"><span class="header-section-number">16.2.1</span> Adjusted \(\mbox{R}^2\)</a></li>
<li><a class="nav-link" href="#likelihood-ratio-test"><span class="header-section-number">16.2.2</span> Likelihood Ratio Test</a></li>
<li><a class="nav-link" href="#aic"><span class="header-section-number">16.2.3</span> AIC</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#laboratory-9"><span class="header-section-number">16.3</span> Laboratory</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#format-penguin-data"><span class="header-section-number">16.3.1</span> Format Penguin Data</a></li>
<li><a class="nav-link" href="#analyze-penguin-data"><span class="header-section-number">16.3.2</span> Analyze Penguin Data</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/aterui/biostats/blob/master/chapters/basics-10-model-comparison.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/aterui/biostats/edit/master/chapters/basics-10-model-comparison.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>BIOSTATS</strong>" was written by Akira Terui. It was last built on 2025-11-18.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
